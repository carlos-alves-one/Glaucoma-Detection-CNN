{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOkgX1KcZKW2Hif8SNtU9I6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlos-alves-one/-AI-Coursework-1/blob/main/glaucoma_detection_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goldsmiths University of London\n",
        "### MSc. Data Science and Artificial Intelligence\n",
        "### Module: Artificial Intelligence\n",
        "### Author: Carlos Manuel De Oliveira Alves\n",
        "### Student: cdeol003\n",
        "### Coursework No.1"
      ],
      "metadata": {
        "id": "tBKBzWjS13MG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Project\n",
        "VisionGuard AI: Deep Learning for Early Glaucoma Detection"
      ],
      "metadata": {
        "id": "Fbvq5jygCiJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "q7mllJDHrgkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this research is to outline the progression of a deep-learning model designed to identify glaucoma through the analysis of ocular pictures. Glaucoma is a debilitating ocular disorder that, if left undetected and untreated in its early stages, can result in complete vision loss. Effective screening procedures are necessary due to the asymptomatic nature of the early stages of glaucoma. Deep learning, specifically convolutional neural networks (CNNs), has demonstrated considerable potential in image identification tasks and can aid in the early detection of glaucoma. The dataset utilised in this research comprises a collection of ocular pictures accompanied by a binary classification showing the presence or absence of glaucoma. The ExpCDR, or 'Cup to Disc Ratio', is a crucial clinical parameter utilised in evaluating glaucoma for each image."
      ],
      "metadata": {
        "id": "5nmnsNVsr8qW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology"
      ],
      "metadata": {
        "id": "3b-dTV8Vt49g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "MY2ytKpmt738"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The photos will undergo a process of loading, resizing to a consistent dimension, and normalisation to ensure that their pixel values fall within the range of 0 to 1. Furthermore, it is possible to employ data augmentation methods, such as rotations, shifts, and flips, in order to augment the size and diversity of the dataset. This can be beneficial in mitigating the issue of overfitting."
      ],
      "metadata": {
        "id": "D6BrGaKKuGCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the data"
      ],
      "metadata": {
        "id": "jn_YNcXj8IEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports the 'drive' module from 'google.colab' and mounts the Google Drive to\n",
        "# the '/content/drive' directory in the Colab environment.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKsi5_1N_kOj",
        "outputId": "1acb335d-ab6f-4d37-8b3c-c07b9778cc78"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pandas library and give it the alias 'pd' for data manipulation and analysis\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset glaucoma from Google Drive\n",
        "data_path = '/content/drive/MyDrive/glaucoma.csv'\n",
        "glaucoma_data = pd.read_csv(data_path)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "glaucoma_data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "izSxt6H1yRKF",
        "outputId": "5c439a17-afb3-46de-fa8c-0aef6034bd68"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Filename  ExpCDR Eye Set  Glaucoma\n",
              "0  001.jpg  0.7097  OD   A         0\n",
              "1  002.jpg  0.6953  OS   A         0\n",
              "2  003.jpg  0.9629  OS   A         0\n",
              "3  004.jpg  0.7246  OD   A         0\n",
              "4  005.jpg  0.6138  OS   A         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-056b56f3-1eb4-4f73-bd19-17561400a206\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>ExpCDR</th>\n",
              "      <th>Eye</th>\n",
              "      <th>Set</th>\n",
              "      <th>Glaucoma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001.jpg</td>\n",
              "      <td>0.7097</td>\n",
              "      <td>OD</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002.jpg</td>\n",
              "      <td>0.6953</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>003.jpg</td>\n",
              "      <td>0.9629</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004.jpg</td>\n",
              "      <td>0.7246</td>\n",
              "      <td>OD</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>005.jpg</td>\n",
              "      <td>0.6138</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-056b56f3-1eb4-4f73-bd19-17561400a206')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-056b56f3-1eb4-4f73-bd19-17561400a206 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-056b56f3-1eb4-4f73-bd19-17561400a206');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-04aa0fd4-e526-4e34-8737-fc83df967ef3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-04aa0fd4-e526-4e34-8737-fc83df967ef3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-04aa0fd4-e526-4e34-8737-fc83df967ef3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset source: https://www.kaggle.com/datasets/sshikamaru/glaucoma-detection"
      ],
      "metadata": {
        "id": "0Wkii1gYzyP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "License: CC0 - Public Domain\n",
        "https://creativecommons.org/publicdomain/zero/1.0/"
      ],
      "metadata": {
        "id": "aH2Ggn2F1iVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains the following columns:\n",
        "\n",
        "    - Filename: The name of the image file.\n",
        "    - ExpCDR: The 'Cup to Disc Ratio', a crucial parameter for evaluating glaucoma.\n",
        "    - Eye: Indicates which eye the image corresponds to (OD for right eye, OS for left eye).\n",
        "    - Set: This could denote the dataset split (e.g., training, validation, or test set), but we would need further clarification.\n",
        "    - Glaucoma: The binary label indicating the presence (1) or absence (0) of glaucoma."
      ],
      "metadata": {
        "id": "R7pF7QJBzWJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocess the Data"
      ],
      "metadata": {
        "id": "kIRg-zv18Wdc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declare function to preprocess a single image:"
      ],
      "metadata": {
        "id": "G3MorKQz8imc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the os module for interacting with the operating system and tensorflow for machine learning tasks\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Function to preprocess a single image\n",
        "def preprocess_image(filename, img_height=224, img_width=224, images_directory='/content/drive/MyDrive/Images'):\n",
        "\n",
        "    # Join the directory path and filename to form the full path to an image\n",
        "    image_path = os.path.join(images_directory, filename)\n",
        "\n",
        "    # Read the image file from the specified path into a tensor\n",
        "    image = tf.io.read_file(image_path)\n",
        "\n",
        "    # Decode the JPEG image and ensure it has 3 color channels (RGB)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "    # Resize the image to the specified height and width using TensorFlow's resize function\n",
        "    image = tf.image.resize(image, [img_height, img_width])\n",
        "\n",
        "    # Normalize the image pixels to the range 0-1 for model compatibility\n",
        "    image = image / 255.0\n",
        "\n",
        "    # Return image preprocessed\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "8Cor34I5zW5T"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Augmentation"
      ],
      "metadata": {
        "id": "GRaJvgNZA7Kq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up data augmentation using the ImageDataGenerator class from tf.keras.preprocessing.image."
      ],
      "metadata": {
        "id": "GvGPtNgGBH2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the ImageDataGenerator class from TensorFlow's Keras API for real-time data augmentation of images\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set up data augmentation\n",
        "data_augmentation = ImageDataGenerator(\n",
        "\n",
        "    # Configures the image augmentation by rotating images within 20 degrees randomly\n",
        "    rotation_range=20,\n",
        "\n",
        "    # Specifies that the input width can be shifted by a maximum of 20% either left or right\n",
        "    width_shift_range=0.2,\n",
        "\n",
        "    # Randomly shift the height of images during training by a factor of 20%\n",
        "    height_shift_range=0.2,\n",
        "\n",
        "    # Enables horizontal and vertical flipping of images\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "egiwJVWcBHCW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Apply Preprocessing and Augmentation to Dataset"
      ],
      "metadata": {
        "id": "vOjBVhxXCtOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract filenames and corresponding glaucoma presence labels from the dataset\n",
        "filenames = glaucoma_data['Filename'].values\n",
        "labels = glaucoma_data['Glaucoma'].values\n",
        "\n",
        "# A placeholder for the images directory\n",
        "images_directory = '/content/drive/MyDrive/Images'\n",
        "\n",
        "# Preprocess all images\n",
        "images = [preprocess_image(f, images_directory=images_directory) for f in filenames]\n",
        "\n",
        "# Convert to Tensor\n",
        "images = tf.stack(images)\n",
        "labels = tf.convert_to_tensor(labels)\n"
      ],
      "metadata": {
        "id": "zRzwzMliCuaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Split the data\n",
        "The dataset will be split into training, validation, and test sets. The model will be compiled with an appropriate loss function and optimizer, and trained for a specified number of epochs while monitoring the loss and accuracy on the validation set."
      ],
      "metadata": {
        "id": "MMpzilotV5-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split function from scikit-learn to split data into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import TensorFlow for deep learning and train_test_split function for splitting the dataset into training and testing sets\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Convert image and label tensors to numpy arrays for further manipulation or analysis\n",
        "images_numpy = images.numpy()\n",
        "labels_numpy = labels.numpy()\n",
        "\n",
        "# Split the dataset into training set and a combined validation/test set with a 20% size of the original dataset,\n",
        "# using a fixed random state for reproducibility.\n",
        "train_images, val_test_images, train_labels, val_test_labels = train_test_split(\n",
        "    images_numpy, labels_numpy, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Split the val_test set equally into validation and test sets (50% validation, 50% test)\n",
        "val_images, test_images, val_labels, test_labels = train_test_split(\n",
        "    val_test_images, val_test_labels, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "emTnln6HQhGF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture\n",
        "The model will be a CNN, known for its performance in image classification tasks. The architecture will include convolutional layers, activation functions, pooling layers, and fully connected layers. Dropout layers may be included to reduce overfitting."
      ],
      "metadata": {
        "id": "1rw1b7WzG_P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow and essential layers for building a Convolutional Neural Network (CNN)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the CNN model architecture:\n",
        "\n",
        "# This function defines a model with the given input shape\n",
        "def build_model(input_shape):\n",
        "\n",
        "    # Initialize a Sequential model\n",
        "    model = Sequential([\n",
        "\n",
        "        # Add a 2D convolution layer with 32 filters of size 3x3 and ReLU activation function\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "\n",
        "        # Add a max pooling layer with pool size of 2x2 to reduce spatial dimensions\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        # Add another 2D convolution layer with 64 filters of size 3x3 and ReLU activation function\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "\n",
        "        # Add another max pooling layer with pool size of 2x2 to reduce spatial dimensions\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        # Add a third 2D convolution layer with 128 filters of size 3x3 and ReLU activation function\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "\n",
        "        # Add another max pooling layer with pool size of 2x2 to further reduce spatial dimensions\n",
        "        MaxPooling2D((2, 2)),\n",
        "\n",
        "        # Flatten the multi-dimensional input to a one-dimensional array\n",
        "        Flatten(),\n",
        "\n",
        "        # Add a densely connected layer with 128 units and ReLU activation function\n",
        "        Dense(128, activation='relu'),\n",
        "\n",
        "        # Add a dropout layer with a dropout rate of 0.5 to prevent overfitting\n",
        "        Dropout(0.5),\n",
        "\n",
        "        # Add a densely connected output layer with 1 unit and a sigmoid activation function for binary classification\n",
        "        Dense(1, activation='sigmoid')  # Sigmoid activation for binary classification\n",
        "    ])\n",
        "\n",
        "    # Return the constructed model\n",
        "    return model\n",
        "\n",
        "# Assuming the input images are 224x224 pixels with 3 channels (RGB)\n",
        "input_shape = (224, 224, 3)\n",
        "model = build_model(input_shape)\n"
      ],
      "metadata": {
        "id": "4SBIwCjOPxyR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Process\n",
        "The model will be compiled with an appropriate loss function and optimizer, and trained for a specified number of epochs while monitoring the loss and accuracy on the validation set."
      ],
      "metadata": {
        "id": "k7aEha11HqEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model:\n",
        "\n",
        "model.compile(optimizer='adam',             # Set 'adam' optimizer for the training process\n",
        "              loss='binary_crossentropy',   # Use 'binary_crossentropy' as the loss function for binary classification\n",
        "              metrics=['accuracy'])         # Track 'accuracy' as a metric to evaluate the model's performance\n",
        "\n",
        "# Specify the batch size and number of epochs for training\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(val_images, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCOFTCbSWtow",
        "outputId": "e5f81828-9692-4d48-d8f7-6c30094c2b5b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "17/17 [==============================] - 79s 4s/step - loss: 0.6382 - accuracy: 0.6808 - val_loss: 0.6608 - val_accuracy: 0.7538\n",
            "Epoch 2/10\n",
            "17/17 [==============================] - 65s 4s/step - loss: 0.6333 - accuracy: 0.7231 - val_loss: 0.5825 - val_accuracy: 0.7538\n",
            "Epoch 3/10\n",
            "17/17 [==============================] - 57s 3s/step - loss: 0.5719 - accuracy: 0.7423 - val_loss: 0.5645 - val_accuracy: 0.7538\n",
            "Epoch 4/10\n",
            "17/17 [==============================] - 67s 4s/step - loss: 0.5861 - accuracy: 0.7423 - val_loss: 0.5718 - val_accuracy: 0.7538\n",
            "Epoch 5/10\n",
            "17/17 [==============================] - 60s 4s/step - loss: 0.5857 - accuracy: 0.7423 - val_loss: 0.5801 - val_accuracy: 0.7538\n",
            "Epoch 6/10\n",
            "17/17 [==============================] - 59s 3s/step - loss: 0.5882 - accuracy: 0.7423 - val_loss: 0.5734 - val_accuracy: 0.7538\n",
            "Epoch 7/10\n",
            "17/17 [==============================] - 60s 4s/step - loss: 0.5890 - accuracy: 0.7423 - val_loss: 0.5645 - val_accuracy: 0.7538\n",
            "Epoch 8/10\n",
            "17/17 [==============================] - 66s 4s/step - loss: 0.5641 - accuracy: 0.7423 - val_loss: 0.5831 - val_accuracy: 0.7538\n",
            "Epoch 9/10\n",
            "17/17 [==============================] - 59s 4s/step - loss: 0.5637 - accuracy: 0.7423 - val_loss: 0.5660 - val_accuracy: 0.7538\n",
            "Epoch 10/10\n",
            "17/17 [==============================] - 70s 4s/step - loss: 0.5510 - accuracy: 0.7462 - val_loss: 0.5946 - val_accuracy: 0.7231\n"
          ]
        }
      ]
    }
  ]
}