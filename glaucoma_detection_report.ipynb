{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlos-alves-one/-AI-Coursework-2/blob/main/glaucoma_detection_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goldsmiths University of London\n",
        "### MSc. Data Science and Artificial Intelligence\n",
        "### Module: Artificial Intelligence\n",
        "### Author: Carlos Manuel De Oliveira Alves\n",
        "### Student: cdeol003\n",
        "### Coursework No.2"
      ],
      "metadata": {
        "id": "xzMEUBjqyD2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Project\n",
        "VisionGuard AI: Deep Learning for Early Glaucoma Detection"
      ],
      "metadata": {
        "id": "3m_s3jj2ykLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "dKmrlfDHyrBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Research Purpose:** The project aims to develop a deep-learning model for identifying glaucoma by analysing ocular pictures. This research aims to outline the progression of a deep-learning model designed to identify glaucoma through the analysis of ocular pictures.\n",
        "\n",
        "- **Relevance of the Problem:** Glaucoma is a severe ocular disorder that can lead to complete vision loss if not detected early. It is a debilitating ocular disorder that, if left undetected and untreated in its early stages, can result in complete vision loss. Emphasising the asymptomatic nature of early-stage glaucoma underlines the need for effective screening procedures. Effective screening procedures are necessary due to the asymptomatic nature of the early stages of glaucoma.\n",
        "\n",
        "- **Role of Deep Learning:** For this project, we use convolutional neural networks (CNNs), a popular deep learning technique, especially for image identification tasks. Deep learning, specifically convolutional neural networks (CNNs), has demonstrated considerable potential in image identification tasks and can aid in the early detection of glaucoma.\n",
        "\n",
        "- **Dataset Description** The dataset comprises ocular pictures with a binary classification indicating the presence or absence of glaucoma. The dataset utilised in this research comprises a collection of ocular pictures accompanied by a binary classification showing the presence or absence of glaucoma.\n",
        "\n",
        "- **Key Clinical Parameter - ExpCDR:** The 'Cup to Disc Ratio' (ExpCDR) is a crucial clinical parameter for evaluating glaucoma in each image, and it is insightful. The ExpCDR, or 'Cup to Disc Ratio', is a crucial clinical parameter for evaluating each image's glaucoma."
      ],
      "metadata": {
        "id": "J2ATgtijyt6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology"
      ],
      "metadata": {
        "id": "Z_0kKAKPzUBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "KrJPhnITCbvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The photos will undergo a process of loading, resizing to a consistent dimension, and normalisation to ensure that their pixel values fall within the range of 0 to 1. Furthermore, it is possible to employ data augmentation methods, such as rotations, shifts, and flips, in order to augment the size and diversity of the dataset. This can be beneficial in mitigating the issue of overfitting."
      ],
      "metadata": {
        "id": "GolCWF_9Cc05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the data"
      ],
      "metadata": {
        "id": "vJxQknsHCnRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports the 'drive' module from 'google.colab' and mounts the Google Drive to\n",
        "# the '/content/drive' directory in the Colab environment.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8qRwA8fCpGx",
        "outputId": "50a22d7e-bed7-4698-cdbf-da97e2be7147"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pandas library and give it the alias 'pd' for data manipulation and analysis\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset glaucoma from Google Drive\n",
        "data_path = '/content/drive/MyDrive/glaucoma_project/glaucoma.csv'\n",
        "glaucoma_data = pd.read_csv(data_path)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "glaucoma_data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yITsqdLEC_td",
        "outputId": "bb255867-9368-4778-fdcc-de8f2ff9c1b1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Filename  ExpCDR Eye Set  Glaucoma\n",
              "0  001.jpg  0.7097  OD   A         0\n",
              "1  002.jpg  0.6953  OS   A         0\n",
              "2  003.jpg  0.9629  OS   A         0\n",
              "3  004.jpg  0.7246  OD   A         0\n",
              "4  005.jpg  0.6138  OS   A         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1dd8802c-0179-4b7a-b542-da85b4e03d28\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>ExpCDR</th>\n",
              "      <th>Eye</th>\n",
              "      <th>Set</th>\n",
              "      <th>Glaucoma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001.jpg</td>\n",
              "      <td>0.7097</td>\n",
              "      <td>OD</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002.jpg</td>\n",
              "      <td>0.6953</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>003.jpg</td>\n",
              "      <td>0.9629</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004.jpg</td>\n",
              "      <td>0.7246</td>\n",
              "      <td>OD</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>005.jpg</td>\n",
              "      <td>0.6138</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1dd8802c-0179-4b7a-b542-da85b4e03d28')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1dd8802c-0179-4b7a-b542-da85b4e03d28 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1dd8802c-0179-4b7a-b542-da85b4e03d28');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ddbce2f4-07d7-4d81-9d4f-37e8256fdac9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ddbce2f4-07d7-4d81-9d4f-37e8256fdac9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ddbce2f4-07d7-4d81-9d4f-37e8256fdac9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset source: https://www.kaggle.com/datasets/sshikamaru/glaucoma-detection"
      ],
      "metadata": {
        "id": "fZNyLGQ_DPGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "License: CC0 - Public Domain\n",
        "https://creativecommons.org/publicdomain/zero/1.0/"
      ],
      "metadata": {
        "id": "3M4yTljuDRJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains the following columns:\n",
        "\n",
        "    - Filename: The name of the image file.\n",
        "    - ExpCDR: The 'Cup to Disc Ratio', a crucial parameter for evaluating glaucoma.\n",
        "    - Eye: Indicates which eye the image corresponds to (OD for right eye, OS for left eye).\n",
        "    - Set: This could denote the dataset split (e.g., training, validation, or test set), but we would need further clarification.\n",
        "    - Glaucoma: The binary label indicating the presence (1) or absence (0) of glaucoma."
      ],
      "metadata": {
        "id": "xMxYuhP8Dzz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Set a Random Seed\n",
        "\n",
        "Deep learning models rely on random number generation for initializing weights, splitting data, and other stochastic processes. Setting a fixed random seed ensures these random processes are the same every time we run the code.# Import the NumPy library for numerical operations\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5HQDB80K34rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the NumPy library for numerical operations\n",
        "import numpy as np\n",
        "\n",
        "# Import the random module for generating pseudo-random numbers\n",
        "import random\n",
        "\n",
        "# Importing the os module for interacting with the operating system and tensorflow for machine learning tasks\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set a seed value\n",
        "seed_value = 123\n",
        "\n",
        "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "\n",
        "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set `numpy` pseudo-random generator at a fixed value\n"
      ],
      "metadata": {
        "id": "dekSF3pm39km"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocess the Data"
      ],
      "metadata": {
        "id": "a1p9dD7TAZkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declare function to preprocess a single image:\n",
        "\n",
        "The following code snippet presents a Python script that use TensorFlow for the purpose of picture preparation. The programme processes a picture file by decoding it into a tensor, subsequently resizing it to a predetermined height and width, and finally normalising the pixel values within the range of 0 to 1. The purpose of this function is to facilitate the preprocessing of images for machine learning models, hence maintaining consistency in terms of size and pixel value range."
      ],
      "metadata": {
        "id": "LS9WwTdJAesI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess a single image\n",
        "def preprocess_image(filename, img_height=224, img_width=224, images_directory='/content/drive/MyDrive/glaucoma_project/images'):\n",
        "\n",
        "    # Join the directory path and filename to form the full path to an image\n",
        "    image_path = os.path.join(images_directory, filename)\n",
        "\n",
        "    # Read the image file from the specified path into a tensor\n",
        "    image = tf.io.read_file(image_path)\n",
        "\n",
        "    # Decode the JPEG image and ensure it has 3 color channels (RGB)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "    # Resize the image to the specified height and width using TensorFlow's resize function\n",
        "    image = tf.image.resize(image, [img_height, img_width])\n",
        "\n",
        "    # Normalize the image pixels to the range 0-1 for model compatibility\n",
        "    image = image / 255.0\n",
        "\n",
        "    # Return image preprocessed\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "w1RNnhFaAmiH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Augmentation"
      ],
      "metadata": {
        "id": "aav0Y_8yBIF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Set up data augmentation using the ImageDataGenerator class from tf.keras.preprocessing.image:\n",
        "\n",
        " The code that follows the snippet demonstrates the utilisation of TensorFlow's Keras API to initialise an image data augmentation pipeline. More specifically, it employs the ImageDataGenerator class. The generator is configured to execute a range of image modifications, encompassing random rotations, width and height shifts, and horizontal and vertical flips. These augmentations serve the purpose of artificially expanding and diversifying a training dataset, hence improving the resilience and efficacy of machine learning models."
      ],
      "metadata": {
        "id": "5Thx6cecBJ59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the ImageDataGenerator class from TensorFlow's Keras API for real-time data augmentation of images\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set up data augmentation\n",
        "data_augmentation = ImageDataGenerator(\n",
        "\n",
        "    # Configures the image augmentation by rotating images within 20 degrees randomly\n",
        "    rotation_range=20,\n",
        "\n",
        "    # Specifies that the input width can be shifted by a maximum of 20% either left or right\n",
        "    width_shift_range=0.2,\n",
        "\n",
        "    # Randomly shift the height of images during training by a factor of 20%\n",
        "    height_shift_range=0.2,\n",
        "\n",
        "    # Enables horizontal and vertical flipping of images\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "DeJNp54GBZfR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Apply Preprocessing and Augmentation to Dataset"
      ],
      "metadata": {
        "id": "Ogafn90aB3d2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code extracts image filenames and corresponding labels for glaucoma detection from the dataset, preprocesses the images, and then applies data augmentation techniques like rotation and flipping. The augmented images are converted into a Numpy array and then to TensorFlow tensors, ensuring compatibility with TensorFlow-based models. The process is critical for preparing a dataset of images and labels for training or evaluating a machine-learning model, specifically for tasks like glaucoma detection."
      ],
      "metadata": {
        "id": "H6fgXC6rB5UE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare function to preprocess and augment images for a glaucoma dataset\n",
        "def preprocess_and_augment_images(glaucoma_data, preprocess_image, data_augmentation, images_directory):\n",
        "\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    - glaucoma_data: DataFrame containing filenames and glaucoma labels\n",
        "    - preprocess_image: Function to preprocess a single image\n",
        "    - data_augmentation: Data augmentation generator\n",
        "    - images_directory: Directory where images are stored\n",
        "\n",
        "    Returns:\n",
        "    - Tuple of TensorFlow tensors (images, labels)\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract filenames and corresponding glaucoma presence labels\n",
        "    filenames = glaucoma_data['Filename'].values\n",
        "    labels = glaucoma_data['Glaucoma'].values\n",
        "\n",
        "    # Preprocess all images\n",
        "    preprocessed_images = [preprocess_image(f, images_directory=images_directory) for f in filenames]\n",
        "\n",
        "    # Convert the list of images to a Numpy array\n",
        "    images_np = np.array(preprocessed_images)\n",
        "\n",
        "    # Create a generator for augmentation\n",
        "    augmented_images_generator = data_augmentation.flow(images_np, batch_size=1, shuffle=False)\n",
        "\n",
        "    # Collect augmented images\n",
        "    augmented_images = []\n",
        "    for _ in range(len(preprocessed_images)):\n",
        "        # Get the next augmented image from the generator\n",
        "        augmented_image = next(augmented_images_generator)[0]\n",
        "\n",
        "        # Remove batch dimension and append to list\n",
        "        augmented_images.append(augmented_image)\n",
        "\n",
        "    # Convert the list of augmented images to a Tensor\n",
        "    images = tf.stack(augmented_images)\n",
        "\n",
        "    # Convert labels to Tensor\n",
        "    labels = tf.convert_to_tensor(labels)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Execute the function to preprocess and augment images for a glaucoma dataset.\n",
        "images, labels = preprocess_and_augment_images(glaucoma_data, preprocess_image, data_augmentation, '/content/drive/MyDrive/glaucoma_project/images')\n",
        "\n",
        "# Convert the list of augmented images to a Tensor\n",
        "images = tf.stack(images)\n",
        "\n",
        "# Convert labels to Tensor\n",
        "labels = tf.convert_to_tensor(labels)\n"
      ],
      "metadata": {
        "id": "VHGyoTKtCNFk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Split the Data\n",
        "The dataset will be split into training, validation, and test sets. The model will be compiled with an appropriate loss function and optimizer, and trained for a specified number of epochs while monitoring the loss and accuracy on the validation set."
      ],
      "metadata": {
        "id": "TL6xQLR2EgG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split function from scikit-learn to split data into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import TensorFlow for deep learning and train_test_split function for splitting the dataset into training and testing sets\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Declare function for splits image and label data into training, validation, and test sets\n",
        "def split_dataset(images, labels, test_size=0.2, val_size=0.5, random_state=42):\n",
        "\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    - images: TensorFlow tensor of images\n",
        "    - labels: TensorFlow tensor of labels\n",
        "    - test_size: Proportion of the dataset to include in the test split\n",
        "    - val_size: Proportion of the test split to use for validation\n",
        "    - random_state: Controls the shuffling applied to the data before applying the split\n",
        "\n",
        "    Returns:\n",
        "    - A tuple of numpy arrays: (train_images, val_images, test_images, train_labels, val_labels, test_labels)\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert image and label tensors to numpy arrays\n",
        "    images_numpy = images.numpy()\n",
        "    labels_numpy = labels.numpy()\n",
        "\n",
        "    # Split the dataset into training and combined validation/test sets\n",
        "    train_images, val_test_images, train_labels, val_test_labels = train_test_split(\n",
        "        images_numpy, labels_numpy, test_size=test_size, random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Further split the validation/test set into validation and test sets\n",
        "    val_images, test_images, val_labels, test_labels = train_test_split(\n",
        "        val_test_images, val_test_labels, test_size=val_size, random_state=random_state\n",
        "    )\n",
        "\n",
        "    return train_images, val_images, test_images, train_labels, val_labels, test_labels\n",
        "\n",
        "# Execute function split dataset to split the dataset\n",
        "train_images, val_images, test_images, train_labels, val_labels, test_labels = split_dataset(images, labels)\n"
      ],
      "metadata": {
        "id": "Hpd2KKLLEiGg"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Apply One-Hot Encoded"
      ],
      "metadata": {
        "id": "7DwAliJNugzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code defines a function `convert_to_one_hot` to transform label data into a one-hot encoded format, a standard preprocessing step for classification tasks in machine learning. It calculates the number of unique classes in the training labels and then applies one-hot encoding to the training, validation, and test labels using TensorFlow's utility function. Finally, the function converts the provided label sets into their one-hot encoded counterparts, facilitating their use in training neural network models."
      ],
      "metadata": {
        "id": "CfEeWHQOu6rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare a function to converts label data to one-hot encoded format\n",
        "def convert_to_one_hot(train_labels, val_labels, test_labels):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    - train_labels: Numpy array of training labels\n",
        "    - val_labels: Numpy array of validation labels\n",
        "    - test_labels: Numpy array of test labels\n",
        "\n",
        "    Returns:\n",
        "    - A tuple of one-hot encoded labels: (train_labels, val_labels, test_labels)\n",
        "    \"\"\"\n",
        "\n",
        "    # Determine the number of unique classes in the training labels\n",
        "    num_classes = len(np.unique(train_labels))\n",
        "\n",
        "    # Convert labels to one-hot encoded format\n",
        "    train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=num_classes)\n",
        "    val_labels = tf.keras.utils.to_categorical(val_labels, num_classes=num_classes)\n",
        "    test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n",
        "\n",
        "    return train_labels, val_labels, test_labels\n",
        "\n",
        "# Execute the function to converts label data to one-hot encoded format\n",
        "train_labels, val_labels, test_labels = convert_to_one_hot(train_labels, val_labels, test_labels)\n"
      ],
      "metadata": {
        "id": "CdV8GfXmHtiz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check Balance of the Dataset"
      ],
      "metadata": {
        "id": "STqi4FCHIQI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the balance of the dataset\n",
        "class_distribution = glaucoma_data['Glaucoma'].value_counts()\n",
        "\n",
        "# Print the distribution\n",
        "print(f\"Distribution:\\n{class_distribution}\\n\")\n",
        "\n",
        "# Optionally, calculate the percentage of each class\n",
        "class_percentage = class_distribution / len(glaucoma_data) * 100\n",
        "print(f\"Percentage of each class:\\n{class_percentage}\\n\")\n",
        "\n",
        "# Print the results of the dataset\n",
        "print(f\"Number of instances without Glaucoma (0)..: {class_distribution.loc[0]}\")\n",
        "print(f\"Number of instances with Glaucoma (1).....: {class_distribution.loc[1]}\")\n",
        "print(f\"Percentage without Glaucoma (0)...........: {class_percentage.loc[0]:.2f}%\")\n",
        "print(f\"Percentage with Glaucoma (1)..............: {class_percentage.loc[1]:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkmohC3CF7Z8",
        "outputId": "912343a0-534c-45a3-a7af-3eaeaf99b230"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution:\n",
            "0    482\n",
            "1    168\n",
            "Name: Glaucoma, dtype: int64\n",
            "\n",
            "Percentage of each class:\n",
            "0    74.153846\n",
            "1    25.846154\n",
            "Name: Glaucoma, dtype: float64\n",
            "\n",
            "Number of instances without Glaucoma (0)..: 482\n",
            "Number of instances with Glaucoma (1).....: 168\n",
            "Percentage without Glaucoma (0)...........: 74.15%\n",
            "Percentage with Glaucoma (1)..............: 25.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Oversampling the Dataset"
      ],
      "metadata": {
        "id": "sS__m6I_KTlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the balance of the dataset\n",
        "class_distribution = glaucoma_data['Glaucoma'].value_counts()\n",
        "print(f\"Class Distribution before balancing:\\n{class_distribution}\\n\")\n",
        "\n",
        "# [Code to preprocess image remains unchanged]\n",
        "\n",
        "# [Assuming you choose to balance by oversampling the minority class]\n",
        "\n",
        "# Separate the dataset into two based on the class\n",
        "class_0 = glaucoma_data[glaucoma_data['Glaucoma'] == 0]\n",
        "class_1 = glaucoma_data[glaucoma_data['Glaucoma'] == 1]\n",
        "\n",
        "# Oversample the minority class. For example, if class_1 is the minority:\n",
        "oversampled_class_1 = class_1.sample(len(class_0), replace=True)\n",
        "\n",
        "# Combine the oversampled class with the other class\n",
        "balanced_glaucoma_data = pd.concat([class_0, oversampled_class_1])\n",
        "\n",
        "# Shuffle the dataset to mix the oversampled data\n",
        "balanced_glaucoma_data = balanced_glaucoma_data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Check the new balance of the dataset\n",
        "new_class_distribution = balanced_glaucoma_data['Glaucoma'].value_counts()\n",
        "print(f\"Class Distribution after balancing:\\n{new_class_distribution}\\n\")\n",
        "\n",
        "# Update the initial dataset with the balanced dataset\n",
        "glaucoma_data = balanced_glaucoma_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr1-YMlyKNGQ",
        "outputId": "d4bf0334-ffcd-472e-d48f-963c07186304"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution before balancing:\n",
            "0    482\n",
            "1    168\n",
            "Name: Glaucoma, dtype: int64\n",
            "\n",
            "Class Distribution after balancing:\n",
            "1    482\n",
            "0    482\n",
            "Name: Glaucoma, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Apply Preprocessing and Augumentation to Dataset"
      ],
      "metadata": {
        "id": "iAxuPfbPndOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the function to preprocess and augment images for a glaucoma dataset.\n",
        "images, labels = preprocess_and_augment_images(glaucoma_data, preprocess_image, data_augmentation, '/content/drive/MyDrive/glaucoma_project/images')\n",
        "\n",
        "# Convert the list of augmented images to a Tensor\n",
        "images = tf.stack(images)\n",
        "\n",
        "# Convert labels to Tensor\n",
        "labels = tf.convert_to_tensor(labels)\n"
      ],
      "metadata": {
        "id": "RZYrr_sAnUW-"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Split the Data"
      ],
      "metadata": {
        "id": "jg__9o-LoOjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute function split dataset to split the dataset\n",
        "train_images, val_images, test_images, train_labels, val_labels, test_labels = split_dataset(images, labels)\n"
      ],
      "metadata": {
        "id": "cdt_4AY2oSuV"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Apply One-Hot Encoded"
      ],
      "metadata": {
        "id": "-ingWbg1vRF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the function to converts label data to one-hot encoded format\n",
        "train_labels, val_labels, test_labels = convert_to_one_hot(train_labels, val_labels, test_labels)\n"
      ],
      "metadata": {
        "id": "GWFE6DVjspKa"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture\n",
        "The model will be a CNN, known for its performance in image classification tasks. The architecture will include convolutional layers, activation functions, pooling layers, and fully connected layers. Dropout layers may be included to reduce overfitting."
      ],
      "metadata": {
        "id": "ODQzViI7FQBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model is a relatively simple Convolutional Neural Network (CNN) model designed for image classification tasks. It has been built using TensorFlow and Keras, and the architecture is straightforward, making it suitable for small to medium-sized datasets and a starting point for more complex tasks. Here is a breakdown of the model:\n",
        "\n",
        "1. Input Layer: Accepts images of size 224x224 with three colour channels (RGB).\n",
        "2. Convolutional Layers:\n",
        "   - The first convolutional layer has 32 filters of size 3x3 with ReLU activation.\n",
        "   - The second convolutional layer has 64 filters of size 3x3 with ReLU activation.\n",
        "   - The third convolutional layer has 128 filters of size 3x3 with ReLU activation.\n",
        "3. Pooling Layers: Two max-pooling layers are used to reduce the spatial dimensions of the feature maps.\n",
        "4. Flatten Layer: Flattens the output for the dense layer.\n",
        "5. Output Layer: A dense layer with some neurons equal to the number of classes (`num_classes`), using softmax activation for multi-class classification.\n",
        "\n",
        "The model is compiled with the Adam optimizer, categorical cross-entropy loss, and accuracy metric. It has trained for ten epochs with a validation split of 0.1.\n",
        "\n",
        "This model is suitable for learning or initial experimentation with image classification tasks."
      ],
      "metadata": {
        "id": "he-yxuH8SaeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code demonstrates the construction, training, and evaluation of a Convolutional Neural Network (CNN) for image classification using TensorFlow. It includes defining the model architecture with convolutional, pooling, and dense layers, followed by compilation with appropriate loss and optimization functions. The model is then trained on labeled image data, evaluated for accuracy on a test set, and the test accuracy is reported, showcasing the end-to-end process of a typical deep learning image classification task.\n"
      ],
      "metadata": {
        "id": "jBsCq-rNt8Ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare function to Builds, compiles, and trains a convolutional neural network model\n",
        "def build_and_train_model(train_images, train_labels, test_images, test_labels, num_classes, epochs=10, validation_split=0.1):\n",
        "\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    - train_images: Training images.\n",
        "    - train_labels: One-hot encoded training labels.\n",
        "    - test_images: Test images.\n",
        "    - test_labels: One-hot encoded test labels.\n",
        "    - num_classes: Number of classes for classification.\n",
        "    - epochs: Number of epochs for training.\n",
        "    - validation_split: Fraction of the training data to be used as validation data.\n",
        "\n",
        "    Returns:\n",
        "    - The trained model and its test accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input layer\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "    # Convolutional layers with max pooling\n",
        "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "\n",
        "    # Flatten the output\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    # Build the model\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_images, train_labels, epochs=epochs, validation_split=validation_split)\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "\n",
        "    # Print the accuracy results for this model\n",
        "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    return model, test_accuracy\n",
        "\n",
        "# Determine the number of unique classes in the training labels\n",
        "num_classes = len(np.unique(train_labels))\n",
        "\n",
        "# Execute the function to Builds, compiles, and trains a convolutional neural network model\n",
        "model, test_accuracy = build_and_train_model(train_images, train_labels, test_images, test_labels, num_classes, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzxif_lwyxiI",
        "outputId": "159c6295-4fc2-45a8-d030-875d1db9f6b8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 79s 4s/step - loss: 1.0627 - accuracy: 0.5224 - val_loss: 0.6567 - val_accuracy: 0.6410\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 78s 4s/step - loss: 0.6909 - accuracy: 0.5512 - val_loss: 0.6950 - val_accuracy: 0.4359\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 84s 4s/step - loss: 0.6949 - accuracy: 0.5584 - val_loss: 0.6816 - val_accuracy: 0.5897\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 76s 3s/step - loss: 0.6551 - accuracy: 0.6147 - val_loss: 0.7375 - val_accuracy: 0.4487\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 78s 4s/step - loss: 0.5941 - accuracy: 0.6898 - val_loss: 0.8265 - val_accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 79s 4s/step - loss: 0.4837 - accuracy: 0.8009 - val_loss: 1.0667 - val_accuracy: 0.4231\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 79s 4s/step - loss: 0.3380 - accuracy: 0.8442 - val_loss: 1.6139 - val_accuracy: 0.3846\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 75s 3s/step - loss: 0.2577 - accuracy: 0.8874 - val_loss: 1.5514 - val_accuracy: 0.4744\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 82s 4s/step - loss: 0.1888 - accuracy: 0.9177 - val_loss: 2.0991 - val_accuracy: 0.3974\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 78s 4s/step - loss: 0.1361 - accuracy: 0.9481 - val_loss: 2.5861 - val_accuracy: 0.3846\n",
            "4/4 [==============================] - 3s 577ms/step - loss: 2.0083 - accuracy: 0.4845\n",
            "Test accuracy: 0.4845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluate Model Performance"
      ],
      "metadata": {
        "id": "YB0QUOLLSHxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results:**\n",
        "\n",
        "1. **Initial Training Performance:** The training started with a high loss of 1.0627 and a low accuracy of 52.24% in the first epoch.\n",
        "\n",
        "2. **Improvement During Training:** There was a consistent decrease in loss and increase in accuracy for both training (`loss` and `accuracy`) and validation data (`val_loss` and `val_accuracy`), indicating effective learning and generalization.\n",
        "\n",
        "3. **Peak Validation Accuracy:** The highest validation accuracy was 88.74% in the eighth epoch.\n",
        "\n",
        "4. **Test Accuracy Discrepancy:** The test accuracy after the final epoch was significantly lower at 48.45%, suggesting issues with generalization to unseen data.\n",
        "\n",
        "5. **Unexpected Increase in Test Loss:** The final evaluation showed a test loss 2.0083, much higher than any validation loss, indicating possible overfitting or data discrepancy.\n",
        "\n",
        "6. **Consistent Training Time:** The time per step and epoch were stable, showing consistent computational resource usage.\n",
        "\n",
        "**Improvements Needed:**\n",
        "\n",
        "1. **Overfitting Indication:** The increase in validation loss after the eighth epoch and high test loss suggest the model might be overfitting.\n",
        "\n",
        "2. **Generalization Issue:** The low test accuracy compared to validation accuracy indicates a need for better model generalization.\n",
        "\n",
        "3. **Lack of Regularization Techniques:** The absence of regularization techniques or early stopping in the training process might contribute to overfitting.\n",
        "\n",
        "4. **Data Distribution Concerns:** There could be a discrepancy between the test and training/validation data distributions.\n",
        "\n",
        "**Recommendations for Improvement:**\n",
        "\n",
        "1. **Implement Regularization and Early Stopping:** To combat overfitting, introduce regularization techniques and early stopping.\n",
        "\n",
        "2. **Data Augmentation:** Use data augmentation to improve model robustness and generalization.\n",
        "\n",
        "3. **Revise Model Architecture:** Consider a more sophisticated model architecture for better performance.\n",
        "\n",
        "4. **Ensure Data Consistency:** Ensure that the training, validation, and test datasets have similar distributions to avoid data-related issues."
      ],
      "metadata": {
        "id": "a_j2rtvOBGd5"
      }
    }
  ]
}