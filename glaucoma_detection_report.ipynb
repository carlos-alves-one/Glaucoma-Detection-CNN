{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlos-alves-one/-AI-Coursework-2/blob/main/glaucoma_detection_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goldsmiths University of London\n",
        "### MSc. Data Science and Artificial Intelligence\n",
        "### Module: Artificial Intelligence\n",
        "### Author: Carlos Manuel De Oliveira Alves\n",
        "### Student: cdeol003\n",
        "### Coursework No.2"
      ],
      "metadata": {
        "id": "xzMEUBjqyD2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Project\n",
        "VisionGuard AI: Deep Learning for Early Glaucoma Detection"
      ],
      "metadata": {
        "id": "3m_s3jj2ykLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "dKmrlfDHyrBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this research is to outline the progression of a deep-learning model designed to identify glaucoma through the analysis of ocular pictures. Glaucoma is a debilitating ocular disorder that, if left undetected and untreated in its early stages, can result in complete vision loss. Effective screening procedures are necessary due to the asymptomatic nature of the early stages of glaucoma. Deep learning, specifically convolutional neural networks (CNNs), has demonstrated considerable potential in image identification tasks and can aid in the early detection of glaucoma. The dataset utilised in this research comprises a collection of ocular pictures accompanied by a binary classification showing the presence or absence of glaucoma. The ExpCDR, or 'Cup to Disc Ratio', is a crucial clinical parameter utilised in evaluating glaucoma for each image."
      ],
      "metadata": {
        "id": "J2ATgtijyt6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology"
      ],
      "metadata": {
        "id": "Z_0kKAKPzUBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "KrJPhnITCbvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The photos will undergo a process of loading, resizing to a consistent dimension, and normalisation to ensure that their pixel values fall within the range of 0 to 1. Furthermore, it is possible to employ data augmentation methods, such as rotations, shifts, and flips, in order to augment the size and diversity of the dataset. This can be beneficial in mitigating the issue of overfitting."
      ],
      "metadata": {
        "id": "GolCWF_9Cc05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the data"
      ],
      "metadata": {
        "id": "vJxQknsHCnRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports the 'drive' module from 'google.colab' and mounts the Google Drive to\n",
        "# the '/content/drive' directory in the Colab environment.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8qRwA8fCpGx",
        "outputId": "98e5b1aa-39a6-4412-84bb-efe66edbcf7b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pandas library and give it the alias 'pd' for data manipulation and analysis\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset glaucoma from Google Drive\n",
        "data_path = '/content/drive/MyDrive/glaucoma.csv'\n",
        "glaucoma_data = pd.read_csv(data_path)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "glaucoma_data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yITsqdLEC_td",
        "outputId": "c6060f4d-4ce4-4034-aa2c-ed61ed5a1eb6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Filename  ExpCDR Eye Set  Glaucoma\n",
              "0  001.jpg  0.7097  OD   A         0\n",
              "1  002.jpg  0.6953  OS   A         0\n",
              "2  003.jpg  0.9629  OS   A         0\n",
              "3  004.jpg  0.7246  OD   A         0\n",
              "4  005.jpg  0.6138  OS   A         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d369f9cc-55ff-43ea-9867-6e0c4daec039\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>ExpCDR</th>\n",
              "      <th>Eye</th>\n",
              "      <th>Set</th>\n",
              "      <th>Glaucoma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001.jpg</td>\n",
              "      <td>0.7097</td>\n",
              "      <td>OD</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002.jpg</td>\n",
              "      <td>0.6953</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>003.jpg</td>\n",
              "      <td>0.9629</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004.jpg</td>\n",
              "      <td>0.7246</td>\n",
              "      <td>OD</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>005.jpg</td>\n",
              "      <td>0.6138</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d369f9cc-55ff-43ea-9867-6e0c4daec039')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d369f9cc-55ff-43ea-9867-6e0c4daec039 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d369f9cc-55ff-43ea-9867-6e0c4daec039');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-64370351-4792-47b8-9954-b01dc00cdf61\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-64370351-4792-47b8-9954-b01dc00cdf61')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-64370351-4792-47b8-9954-b01dc00cdf61 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset source: https://www.kaggle.com/datasets/sshikamaru/glaucoma-detection"
      ],
      "metadata": {
        "id": "fZNyLGQ_DPGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "License: CC0 - Public Domain\n",
        "https://creativecommons.org/publicdomain/zero/1.0/"
      ],
      "metadata": {
        "id": "3M4yTljuDRJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains the following columns:\n",
        "\n",
        "    - Filename: The name of the image file.\n",
        "    - ExpCDR: The 'Cup to Disc Ratio', a crucial parameter for evaluating glaucoma.\n",
        "    - Eye: Indicates which eye the image corresponds to (OD for right eye, OS for left eye).\n",
        "    - Set: This could denote the dataset split (e.g., training, validation, or test set), but we would need further clarification.\n",
        "    - Glaucoma: The binary label indicating the presence (1) or absence (0) of glaucoma."
      ],
      "metadata": {
        "id": "xMxYuhP8Dzz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Set a Random Seed\n",
        "\n",
        "Deep learning models rely on random number generation for initializing weights, splitting data, and other stochastic processes. Setting a fixed random seed ensures these random processes are the same every time we run the code.# Import the NumPy library for numerical operations\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5HQDB80K34rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the NumPy library for numerical operations\n",
        "import numpy as np\n",
        "\n",
        "# Import the random module for generating pseudo-random numbers\n",
        "import random\n",
        "\n",
        "# Importing the os module for interacting with the operating system and tensorflow for machine learning tasks\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set a seed value\n",
        "seed_value = 123\n",
        "\n",
        "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "\n",
        "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
        "tf.random.set_seed(seed_value)\n",
        "\n",
        "# Additional configurations for TensorFlow to ensure reproducibility\n",
        "# 5. Configure TensorFlow to use deterministic operations where possible\n",
        "# Note: This step might be necessary for some versions of TensorFlow and certain operations\n",
        "# os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "# 6. Limit TensorFlow to a single thread for reproducibility\n",
        "# Note: This might impact performance, only use if necessary\n",
        "# tf.config.threading.set_inter_op_parallelism_threads(1)\n",
        "# tf.config.threading.set_intra_op_parallelism_threads(1)\n",
        "\n",
        "# Additional step if using a GPU with TensorFlow\n",
        "# 7. Set TensorFlow to use only a specific GPU or disable GPU\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Use only the first GPU, for example\n",
        "# or to disable GPU\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = ''   # Disable all GPUs\n"
      ],
      "metadata": {
        "id": "dekSF3pm39km"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocess the Data"
      ],
      "metadata": {
        "id": "a1p9dD7TAZkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declare function to preprocess a single image:\n",
        "\n",
        "The following code snippet presents a Python script that use TensorFlow for the purpose of picture preparation. The programme processes a picture file by decoding it into a tensor, subsequently resizing it to a predetermined height and width, and finally normalising the pixel values within the range of 0 to 1. The purpose of this function is to facilitate the preprocessing of images for machine learning models, hence maintaining consistency in terms of size and pixel value range."
      ],
      "metadata": {
        "id": "LS9WwTdJAesI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess a single image\n",
        "def preprocess_image(filename, img_height=224, img_width=224, images_directory='/content/drive/MyDrive/Images'):\n",
        "\n",
        "    # Join the directory path and filename to form the full path to an image\n",
        "    image_path = os.path.join(images_directory, filename)\n",
        "\n",
        "    # Read the image file from the specified path into a tensor\n",
        "    image = tf.io.read_file(image_path)\n",
        "\n",
        "    # Decode the JPEG image and ensure it has 3 color channels (RGB)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "    # Resize the image to the specified height and width using TensorFlow's resize function\n",
        "    image = tf.image.resize(image, [img_height, img_width])\n",
        "\n",
        "    # Normalize the image pixels to the range 0-1 for model compatibility\n",
        "    image = image / 255.0\n",
        "\n",
        "    # Return image preprocessed\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "w1RNnhFaAmiH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Augmentation"
      ],
      "metadata": {
        "id": "aav0Y_8yBIF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Set up data augmentation using the ImageDataGenerator class from tf.keras.preprocessing.image:\n",
        "\n",
        " The code that follows the snippet demonstrates the utilisation of TensorFlow's Keras API to initialise an image data augmentation pipeline. More specifically, it employs the ImageDataGenerator class. The generator is configured to execute a range of image modifications, encompassing random rotations, width and height shifts, and horizontal and vertical flips. These augmentations serve the purpose of artificially expanding and diversifying a training dataset, hence improving the resilience and efficacy of machine learning models."
      ],
      "metadata": {
        "id": "5Thx6cecBJ59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the ImageDataGenerator class from TensorFlow's Keras API for real-time data augmentation of images\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set up data augmentation\n",
        "data_augmentation = ImageDataGenerator(\n",
        "\n",
        "    # Configures the image augmentation by rotating images within 20 degrees randomly\n",
        "    rotation_range=20,\n",
        "\n",
        "    # Specifies that the input width can be shifted by a maximum of 20% either left or right\n",
        "    width_shift_range=0.2,\n",
        "\n",
        "    # Randomly shift the height of images during training by a factor of 20%\n",
        "    height_shift_range=0.2,\n",
        "\n",
        "    # Enables horizontal and vertical flipping of images\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "DeJNp54GBZfR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Apply Preprocessing and Augmentation to Dataset"
      ],
      "metadata": {
        "id": "Ogafn90aB3d2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code extracts image filenames and corresponding labels for glaucoma detection from the dataset, preprocesses the images, and then applies data augmentation techniques like rotation and flipping. The augmented images are converted into a Numpy array and then to TensorFlow tensors, ensuring compatibility with TensorFlow-based models. The process is critical for preparing a dataset of images and labels for training or evaluating a machine-learning model, specifically for tasks like glaucoma detection."
      ],
      "metadata": {
        "id": "H6fgXC6rB5UE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare function to preprocess and augment images for a glaucoma dataset\n",
        "def preprocess_and_augment_images(glaucoma_data, preprocess_image, data_augmentation, images_directory):\n",
        "\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    - glaucoma_data: DataFrame containing filenames and glaucoma labels\n",
        "    - preprocess_image: Function to preprocess a single image\n",
        "    - data_augmentation: Data augmentation generator\n",
        "    - images_directory: Directory where images are stored\n",
        "\n",
        "    Returns:\n",
        "    - Tuple of TensorFlow tensors (images, labels).\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract filenames and corresponding glaucoma presence labels\n",
        "    filenames = glaucoma_data['Filename'].values\n",
        "    labels = glaucoma_data['Glaucoma'].values\n",
        "\n",
        "    # Preprocess all images\n",
        "    preprocessed_images = [preprocess_image(f, images_directory=images_directory) for f in filenames]\n",
        "\n",
        "    # Convert the list of images to a Numpy array\n",
        "    images_np = np.array(preprocessed_images)\n",
        "\n",
        "    # Create a generator for augmentation\n",
        "    augmented_images_generator = data_augmentation.flow(images_np, batch_size=1, shuffle=False)\n",
        "\n",
        "    # Collect augmented images\n",
        "    augmented_images = []\n",
        "    for _ in range(len(preprocessed_images)):\n",
        "        # Get the next augmented image from the generator\n",
        "        augmented_image = next(augmented_images_generator)[0]\n",
        "\n",
        "        # Remove batch dimension and append to list\n",
        "        augmented_images.append(augmented_image)\n",
        "\n",
        "    # Convert the list of augmented images to a Tensor\n",
        "    images = tf.stack(augmented_images)\n",
        "\n",
        "    # Convert labels to Tensor\n",
        "    labels = tf.convert_to_tensor(labels)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Execute the function to preprocess and augment images for a glaucoma dataset.\n",
        "images, labels = preprocess_and_augment_images(glaucoma_data, preprocess_image, data_augmentation, '/content/drive/MyDrive/Images')\n",
        "\n",
        "# Convert the list of augmented images to a Tensor\n",
        "images = tf.stack(images)\n",
        "\n",
        "# Convert labels to Tensor\n",
        "labels = tf.convert_to_tensor(labels)\n"
      ],
      "metadata": {
        "id": "VHGyoTKtCNFk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Split the Data\n",
        "The dataset will be split into training, validation, and test sets. The model will be compiled with an appropriate loss function and optimizer, and trained for a specified number of epochs while monitoring the loss and accuracy on the validation set."
      ],
      "metadata": {
        "id": "TL6xQLR2EgG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split function from scikit-learn to split data into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import TensorFlow for deep learning and train_test_split function for splitting the dataset into training and testing sets\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Declare function for splits image and label data into training, validation, and test sets\n",
        "def split_dataset(images, labels, test_size=0.2, val_size=0.5, random_state=42):\n",
        "\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    - images: TensorFlow tensor of images\n",
        "    - labels: TensorFlow tensor of labels\n",
        "    - test_size: Proportion of the dataset to include in the test split\n",
        "    - val_size: Proportion of the test split to use for validation\n",
        "    - random_state: Controls the shuffling applied to the data before applying the split\n",
        "\n",
        "    Returns:\n",
        "    - A tuple of numpy arrays: (train_images, val_images, test_images, train_labels, val_labels, test_labels)\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert image and label tensors to numpy arrays\n",
        "    images_numpy = images.numpy()\n",
        "    labels_numpy = labels.numpy()\n",
        "\n",
        "    # Split the dataset into training and combined validation/test sets\n",
        "    train_images, val_test_images, train_labels, val_test_labels = train_test_split(\n",
        "        images_numpy, labels_numpy, test_size=test_size, random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Further split the validation/test set into validation and test sets\n",
        "    val_images, test_images, val_labels, test_labels = train_test_split(\n",
        "        val_test_images, val_test_labels, test_size=val_size, random_state=random_state\n",
        "    )\n",
        "\n",
        "    return train_images, val_images, test_images, train_labels, val_labels, test_labels\n",
        "\n",
        "# Execute function split dataset to split the dataset\n",
        "train_images, val_images, test_images, train_labels, val_labels, test_labels = split_dataset(images, labels)\n"
      ],
      "metadata": {
        "id": "Hpd2KKLLEiGg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Apply One-Hot Encoded"
      ],
      "metadata": {
        "id": "7DwAliJNugzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code defines a function `convert_to_one_hot` to transform label data into a one-hot encoded format, a standard preprocessing step for classification tasks in machine learning. It calculates the number of unique classes in the training labels and then applies one-hot encoding to the training, validation, and test labels using TensorFlow's utility function. Finally, the function converts the provided label sets into their one-hot encoded counterparts, facilitating their use in training neural network models."
      ],
      "metadata": {
        "id": "CfEeWHQOu6rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare a function to converts label data to one-hot encoded format\n",
        "def convert_to_one_hot(train_labels, val_labels, test_labels):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    - train_labels: Numpy array of training labels\n",
        "    - val_labels: Numpy array of validation labels\n",
        "    - test_labels: Numpy array of test labels\n",
        "\n",
        "    Returns:\n",
        "    - A tuple of one-hot encoded labels: (train_labels, val_labels, test_labels)\n",
        "    \"\"\"\n",
        "\n",
        "    # Determine the number of unique classes in the training labels\n",
        "    num_classes = len(np.unique(train_labels))\n",
        "\n",
        "    # Convert labels to one-hot encoded format\n",
        "    train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=num_classes)\n",
        "    val_labels = tf.keras.utils.to_categorical(val_labels, num_classes=num_classes)\n",
        "    test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n",
        "\n",
        "    return train_labels, val_labels, test_labels\n",
        "\n",
        "# Execute the function to converts label data to one-hot encoded format\n",
        "train_labels, val_labels, test_labels = convert_to_one_hot(train_labels, val_labels, test_labels)\n"
      ],
      "metadata": {
        "id": "CdV8GfXmHtiz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture\n",
        "The model will be a CNN, known for its performance in image classification tasks. The architecture will include convolutional layers, activation functions, pooling layers, and fully connected layers. Dropout layers may be included to reduce overfitting."
      ],
      "metadata": {
        "id": "ODQzViI7FQBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model is a relatively simple Convolutional Neural Network (CNN) model designed for image classification tasks. It has been built using TensorFlow and Keras, and the architecture is straightforward, making it suitable for small to medium-sized datasets and a starting point for more complex tasks. Here is a breakdown of the model:\n",
        "\n",
        "1. Input Layer: Accepts images of size 224x224 with three colour channels (RGB).\n",
        "2. Convolutional Layers:\n",
        "   - The first convolutional layer has 32 filters of size 3x3 with ReLU activation.\n",
        "   - The second convolutional layer has 64 filters of size 3x3 with ReLU activation.\n",
        "   - The third convolutional layer has 128 filters of size 3x3 with ReLU activation.\n",
        "3. Pooling Layers: Two max-pooling layers are used to reduce the spatial dimensions of the feature maps.\n",
        "4. Flatten Layer: Flattens the output for the dense layer.\n",
        "5. Output Layer: A dense layer with some neurons equal to the number of classes (`num_classes`), using softmax activation for multi-class classification.\n",
        "\n",
        "The model is compiled with the Adam optimizer, categorical cross-entropy loss, and accuracy metric. It has trained for ten epochs with a validation split of 0.1.\n",
        "\n",
        "This model is suitable for learning or initial experimentation with image classification tasks."
      ],
      "metadata": {
        "id": "he-yxuH8SaeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code demonstrates the construction, training, and evaluation of a Convolutional Neural Network (CNN) for image classification using TensorFlow. It includes defining the model architecture with convolutional, pooling, and dense layers, followed by compilation with appropriate loss and optimization functions. The model is then trained on labeled image data, evaluated for accuracy on a test set, and the test accuracy is reported, showcasing the end-to-end process of a typical deep learning image classification task.\n"
      ],
      "metadata": {
        "id": "jBsCq-rNt8Ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare function to Builds, compiles, and trains a convolutional neural network model\n",
        "def build_and_train_model(train_images, train_labels, test_images, test_labels, num_classes, epochs=10, validation_split=0.1):\n",
        "\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    - train_images: Training images.\n",
        "    - train_labels: One-hot encoded training labels.\n",
        "    - test_images: Test images.\n",
        "    - test_labels: One-hot encoded test labels.\n",
        "    - num_classes: Number of classes for classification.\n",
        "    - epochs: Number of epochs for training.\n",
        "    - validation_split: Fraction of the training data to be used as validation data.\n",
        "\n",
        "    Returns:\n",
        "    - The trained model and its test accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input layer\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "    # Convolutional layers with max pooling\n",
        "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "\n",
        "    # Flatten the output\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    # Build the model\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_images, train_labels, epochs=epochs, validation_split=validation_split)\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "\n",
        "    # Print the accuracy results for this model\n",
        "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    return model, test_accuracy\n",
        "\n",
        "# Determine the number of unique classes in the training labels\n",
        "num_classes = len(np.unique(train_labels))\n",
        "\n",
        "# Execute the function to Builds, compiles, and trains a convolutional neural network model\n",
        "model, test_accuracy = build_and_train_model(train_images, train_labels, test_images, test_labels, num_classes, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzxif_lwyxiI",
        "outputId": "d6086f90-d44f-4d17-88b6-e749d02acfc1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 54s 4s/step - loss: 0.7840 - accuracy: 0.6624 - val_loss: 0.5385 - val_accuracy: 0.8269\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 56s 4s/step - loss: 0.5786 - accuracy: 0.7329 - val_loss: 0.5203 - val_accuracy: 0.8269\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 56s 4s/step - loss: 0.5876 - accuracy: 0.7329 - val_loss: 0.5200 - val_accuracy: 0.8269\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 52s 4s/step - loss: 0.5674 - accuracy: 0.7329 - val_loss: 0.5072 - val_accuracy: 0.8462\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 52s 3s/step - loss: 0.5255 - accuracy: 0.7415 - val_loss: 0.4946 - val_accuracy: 0.8077\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 51s 3s/step - loss: 0.4301 - accuracy: 0.7885 - val_loss: 0.5627 - val_accuracy: 0.8077\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 51s 3s/step - loss: 0.2890 - accuracy: 0.8782 - val_loss: 0.6659 - val_accuracy: 0.6923\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 51s 3s/step - loss: 0.1742 - accuracy: 0.9295 - val_loss: 1.0815 - val_accuracy: 0.6154\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 52s 3s/step - loss: 0.1117 - accuracy: 0.9509 - val_loss: 1.4004 - val_accuracy: 0.5769\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 53s 4s/step - loss: 0.0641 - accuracy: 0.9829 - val_loss: 1.4347 - val_accuracy: 0.6731\n",
            "3/3 [==============================] - 2s 439ms/step - loss: 2.5244 - accuracy: 0.6000\n",
            "Test accuracy: 0.6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluate Model Performance"
      ],
      "metadata": {
        "id": "YB0QUOLLSHxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the matplotlib.pyplot module for plotting graphs and charts\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import the seaborn module for advanced data visualization\n",
        "import seaborn as sns\n",
        "\n",
        "# Importing classification_report and confusion_matrix functions from the scikit-learn metrics module\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Declare function evaluates the given model using test images and labels, plots a confusion matrix and prints a classification report\n",
        "def evaluate_model(model, test_images, test_labels, class_labels=['Not Glaucoma', 'Glaucoma']):\n",
        "\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    - model: Trained TensorFlow/Keras model.\n",
        "    - test_images: Test images.\n",
        "    - test_labels: One-hot encoded test labels.\n",
        "    - class_labels: List of class labels.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    predicted_classes = model.predict(test_images)\n",
        "\n",
        "    # Convert predictions to label indexes\n",
        "    predicted_classes = np.argmax(predicted_classes, axis=1)\n",
        "\n",
        "    # Convert one-hot encoded test labels back to label indexes\n",
        "    true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "    # Generate the confusion matrix\n",
        "    cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "    # Plotting the normalized confusion matrix\n",
        "    plt.figure(figsize=(8, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', vmin=0, cmap='Blues', cbar=True)\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.ylabel('True label')\n",
        "    plt.title('Normalized Confusion Matrix')\n",
        "    plt.xticks(ticks=np.arange(len(class_labels)) + 0.5, labels=class_labels)\n",
        "    plt.yticks(ticks=np.arange(len(class_labels)) + 0.5, labels=class_labels)\n",
        "    plt.show()\n",
        "\n",
        "    # Print the classification report\n",
        "    print(classification_report(true_classes, predicted_classes, target_names=class_labels))\n",
        "\n",
        "# Execute the function evaluate the model and print the results\n",
        "evaluate_model(model, test_images, test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "Vln-ozE56NKd",
        "outputId": "44483482-67d5-4e52-8d64-0af238f63257"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 431ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "Not Glaucoma       0.73      0.70      0.72        47\n",
            "    Glaucoma       0.30      0.33      0.32        18\n",
            "\n",
            "    accuracy                           0.60        65\n",
            "   macro avg       0.52      0.52      0.52        65\n",
            "weighted avg       0.61      0.60      0.61        65\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix for a binary classification problem, where the classes are \"Not Glaucoma\" and \"Glaucoma\". A confusion matrix is a table often used to describe the performance of a classification model on a set of test data for which the true values are known.\n",
        "\n",
        "The matrix shows the following:\n",
        "\n",
        "- True Negatives (Top Left): 39 cases were correctly predicted as \"Not Glaucoma\".\n",
        "- False Positives (Top Right): 8 cases were incorrectly predicted as \"Glaucoma\" when they were actually \"Not Glaucoma\".\n",
        "- False Negatives (Bottom Left): 13 cases were incorrectly predicted as \"Not Glaucoma\" when they were actually \"Glaucoma\".\n",
        "- True Positives (Bottom Right): 5 cases were correctly predicted as \"Glaucoma\".\n",
        "\n",
        "This confusion matrix can calculate performance metrics such as accuracy, precision, recall, and F1 score. It shows that the model is better at predicting the \"Not Glaucoma\" class than the \"Glaucoma\" class, as indicated by the higher number of true negatives compared to true positives and a relatively high number of false negatives.\n",
        "\n",
        "The confusion matrix indicates that the model is significantly better at identifying \"Not Glaucoma\" cases than \"Glaucoma\" cases:\n",
        "\n",
        "1. **Sensitivity (Recall) for 'Glaucoma':** The model correctly identifies 5 out of 18 actual cases of Glaucoma, which gives a recall of approximately 27.8%. This needs to be higher, indicating that the model misses a lot of true Glaucoma cases.\n",
        "\n",
        "2. **Specificity for 'Not Glaucoma':** The model correctly identifies 39 out of 47 actual cases of \"Not Glaucoma\", which means it has a specificity of approximately 83%. This suggests that the model is quite good at identifying negative cases.\n",
        "\n",
        "3. **Precision for 'Glaucoma':** Out of the 13 predicted cases of Glaucoma, only 5 are Glaucoma, leading to a precision of about 38.5%. This indicates that when the model predicts Glaucoma, it is correct only about 38.5% of the time.\n",
        "\n",
        "4. **Accuracy:** The model's overall accuracy can be calculated by taking the sum of the true positives and true negatives and dividing by the total number of cases. In this case, the accuracy is (39 + 5) / (39 + 5 + 13 + 8) = 44 / 65 ≈ 67.7%.\n",
        "\n",
        "The conclusion drawn from this confusion matrix would be that the model is currently more reliable at predicting the absence of Glaucoma than its presence. Given the potential seriousness of missing a Glaucoma diagnosis, the model's ability to identify Glaucoma cases (sensitivity) might need to be improved before it could be used in a clinical setting. Its high specificity is a positive aspect, but the low sensitivity and precision for the 'Glaucoma' class are concerning and suggest that further model tuning, additional training data, or a different model architecture may be required to improve its predictive performance."
      ],
      "metadata": {
        "id": "GmhH_Xv69egF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The classification report provides a summary of the performance metrics for a binary classification model distinguishing between \"Not Glaucoma\" and \"Glaucoma\":\n",
        "\n",
        "1. **Not Glaucoma Class:**\n",
        "   - **Precision:** 0.75 indicates that 75% of \"Not Glaucoma\" predictions were correct.\n",
        "   - **Recall:** 0.83 shows that the model identified 83% of all actual \"Not Glaucoma\" cases.\n",
        "   - **F1-Score:** 0.79 suggests a good balance between precision and recall for the \"Not Glaucoma\" class.\n",
        "   - **Support:** The dataset has 47 instances of the \"Not Glaucoma\" class.\n",
        "\n",
        "2. **Glaucoma Class:**\n",
        "   - **Precision:** 0.38 indicates that when the model predicts \"Glaucoma,\" it is correct 38% of the time.\n",
        "   - **Recall:** 0.28 shows that the model identified 28% of all actual \"Glaucoma\" cases, which is relatively low.\n",
        "   - **F1-Score:** 0.32, a harmonic mean of precision and recall, is also low, indicating that the model is not performing well in the \"Glaucoma\" class.\n",
        "   - **Support:** The dataset has 18 instances of the \"Glaucoma\" class.\n",
        "\n",
        "3. **Overall Metrics:**\n",
        "   - **Accuracy:** The model's overall accuracy is 0.68, meaning it correctly predicts 68% of the outcomes across both classes.\n",
        "   - **Macro Avg:** The macro average for precision is 0.57 and for recall is 0.55, which gives equal weight to both classes regardless of their support.\n",
        "   - **Weighted Avg:** The weighted average for precision is 0.65, and for the F1-score, it is 0.66, which considers each class's support, indicating better performance on the more represented class.\n",
        "\n",
        "The report suggests the model is more reliable at predicting \"Not Glaucoma\" than \"Glaucoma,\" as indicated by the higher scores across precision, recall, and F1-score for the \"Not Glaucoma\" class. The model's ability to identify actual \"Glaucoma\" cases is fragile, which could be problematic in a medical setting where failing to identify \"Glaucoma\" can have serious consequences. This suggests a need for improvement in the model's performance for the \"Glaucoma\" class, possibly through better feature selection, more balanced training data, or advanced modelling techniques."
      ],
      "metadata": {
        "id": "6wnu9yXG-Gpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check Balance of the Dataset"
      ],
      "metadata": {
        "id": "STqi4FCHIQI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the balance of the dataset\n",
        "class_distribution = glaucoma_data['Glaucoma'].value_counts()\n",
        "\n",
        "# Print the distribution\n",
        "print(f\"Distribution:\\n{class_distribution}\\n\")\n",
        "\n",
        "# Optionally, calculate the percentage of each class\n",
        "class_percentage = class_distribution / len(glaucoma_data) * 100\n",
        "print(f\"Percentage of each class:\\n{class_percentage}\\n\")\n",
        "\n",
        "# Print the results of the dataset\n",
        "print(f\"Number of instances without Glaucoma (0)..: {class_distribution.loc[0]}\")\n",
        "print(f\"Number of instances with Glaucoma (1).....: {class_distribution.loc[1]}\")\n",
        "print(f\"Percentage without Glaucoma (0)...........: {class_percentage.loc[0]:.2f}%\")\n",
        "print(f\"Percentage with Glaucoma (1)..............: {class_percentage.loc[1]:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkmohC3CF7Z8",
        "outputId": "63277317-04e0-4c97-aba1-610edf2f7a28"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution:\n",
            "0    482\n",
            "1    168\n",
            "Name: Glaucoma, dtype: int64\n",
            "\n",
            "Percentage of each class:\n",
            "0    74.153846\n",
            "1    25.846154\n",
            "Name: Glaucoma, dtype: float64\n",
            "\n",
            "Number of instances without Glaucoma (0)..: 482\n",
            "Number of instances with Glaucoma (1).....: 168\n",
            "Percentage without Glaucoma (0)...........: 74.15%\n",
            "Percentage with Glaucoma (1)..............: 25.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Oversampling the Dataset"
      ],
      "metadata": {
        "id": "sS__m6I_KTlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the balance of the dataset\n",
        "class_distribution = glaucoma_data['Glaucoma'].value_counts()\n",
        "print(f\"Class Distribution before balancing:\\n{class_distribution}\\n\")\n",
        "\n",
        "# [Code to preprocess image remains unchanged]\n",
        "\n",
        "# [Assuming you choose to balance by oversampling the minority class]\n",
        "\n",
        "# Separate the dataset into two based on the class\n",
        "class_0 = glaucoma_data[glaucoma_data['Glaucoma'] == 0]\n",
        "class_1 = glaucoma_data[glaucoma_data['Glaucoma'] == 1]\n",
        "\n",
        "# Oversample the minority class. For example, if class_1 is the minority:\n",
        "oversampled_class_1 = class_1.sample(len(class_0), replace=True)\n",
        "\n",
        "# Combine the oversampled class with the other class\n",
        "balanced_glaucoma_data = pd.concat([class_0, oversampled_class_1])\n",
        "\n",
        "# Shuffle the dataset to mix the oversampled data\n",
        "balanced_glaucoma_data = balanced_glaucoma_data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Check the new balance of the dataset\n",
        "new_class_distribution = balanced_glaucoma_data['Glaucoma'].value_counts()\n",
        "print(f\"Class Distribution after balancing:\\n{new_class_distribution}\\n\")\n",
        "\n",
        "# Update the initial dataset with the balanced dataset\n",
        "glaucoma_data = balanced_glaucoma_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr1-YMlyKNGQ",
        "outputId": "2de676a0-b850-4e4e-9e93-0680d32a26ff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution before balancing:\n",
            "0    482\n",
            "1    168\n",
            "Name: Glaucoma, dtype: int64\n",
            "\n",
            "Class Distribution after balancing:\n",
            "0    482\n",
            "1    482\n",
            "Name: Glaucoma, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Apply Preprocessing and Augumentation to Dataset"
      ],
      "metadata": {
        "id": "iAxuPfbPndOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the function to preprocess and augment images for a glaucoma dataset.\n",
        "images, labels = preprocess_and_augment_images(glaucoma_data, preprocess_image, data_augmentation, '/content/drive/MyDrive/Images')\n",
        "\n",
        "# Convert the list of augmented images to a Tensor\n",
        "images = tf.stack(images)\n",
        "\n",
        "# Convert labels to Tensor\n",
        "labels = tf.convert_to_tensor(labels)\n"
      ],
      "metadata": {
        "id": "RZYrr_sAnUW-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Split the Data"
      ],
      "metadata": {
        "id": "jg__9o-LoOjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute function split dataset to split the dataset\n",
        "train_images, val_images, test_images, train_labels, val_labels, test_labels = split_dataset(images, labels)\n"
      ],
      "metadata": {
        "id": "cdt_4AY2oSuV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Apply One-Hot Encoded"
      ],
      "metadata": {
        "id": "-ingWbg1vRF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the function to converts label data to one-hot encoded format\n",
        "train_labels, val_labels, test_labels = convert_to_one_hot(train_labels, val_labels, test_labels)\n"
      ],
      "metadata": {
        "id": "GWFE6DVjspKa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train the Model"
      ],
      "metadata": {
        "id": "OW6nz-MFspq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the number of unique classes in the training labels\n",
        "num_classes = len(np.unique(train_labels))\n",
        "\n",
        "# Execute the function to Builds, compiles, and trains a convolutional neural network model\n",
        "model, test_accuracy = build_and_train_model(train_images, train_labels, test_images, test_labels, num_classes, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3lCo2OAvZEh",
        "outputId": "586322a4-c214-4ae4-e22c-46016b4dff6d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 88s 4s/step - loss: 1.0075 - accuracy: 0.5238 - val_loss: 0.6856 - val_accuracy: 0.5513\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 75s 3s/step - loss: 0.6939 - accuracy: 0.5051 - val_loss: 0.6983 - val_accuracy: 0.5256\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 76s 3s/step - loss: 0.6779 - accuracy: 0.5931 - val_loss: 0.7135 - val_accuracy: 0.5128\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 75s 3s/step - loss: 0.5978 - accuracy: 0.6970 - val_loss: 0.7994 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 76s 3s/step - loss: 0.4602 - accuracy: 0.7965 - val_loss: 0.9607 - val_accuracy: 0.4487\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 79s 4s/step - loss: 0.3246 - accuracy: 0.8543 - val_loss: 1.2141 - val_accuracy: 0.4359\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 78s 4s/step - loss: 0.2245 - accuracy: 0.8947 - val_loss: 1.3404 - val_accuracy: 0.4231\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 75s 3s/step - loss: 0.1447 - accuracy: 0.9481 - val_loss: 1.4758 - val_accuracy: 0.4744\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 85s 4s/step - loss: 0.1113 - accuracy: 0.9711 - val_loss: 1.7651 - val_accuracy: 0.5256\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 76s 3s/step - loss: 0.0658 - accuracy: 0.9784 - val_loss: 2.1234 - val_accuracy: 0.4872\n",
            "4/4 [==============================] - 3s 565ms/step - loss: 2.7305 - accuracy: 0.4433\n",
            "Test accuracy: 0.4433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluate Model Performance"
      ],
      "metadata": {
        "id": "NDiOXm5m2P6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the function evaluate the model and print the results\n",
        "evaluate_model(model, test_images, test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "5-cWGhYj2URQ",
        "outputId": "20c510f4-4fb4-4cbe-8382-63f90d0878e0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 4s 1s/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "Not Glaucoma       0.46      0.46      0.46        50\n",
            "    Glaucoma       0.43      0.43      0.43        47\n",
            "\n",
            "    accuracy                           0.44        97\n",
            "   macro avg       0.44      0.44      0.44        97\n",
            "weighted avg       0.44      0.44      0.44        97\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The updated confusion matrix for the binary classification problem indicates the following:\n",
        "\n",
        "1. **True Negatives (Top Left):** 38 cases were correctly predicted as \"Not Glaucoma\".\n",
        "2. **False Positives (Top Right):** 26 cases were incorrectly predicted as \"Glaucoma\" when they were actually \"Not Glaucoma\".\n",
        "3. **False Negatives (Bottom Left):** 13 cases were incorrectly predicted as \"Not Glaucoma\" when they were actually \"Glaucoma\".\n",
        "4. **True Positives (Bottom Right):** 20 cases were correctly predicted as \"Glaucoma\".\n",
        "\n",
        "This matrix shows an improvement in the detection of \"Glaucoma\" compared to the previous matrix, as there are more true positives (20 vs. 5 previously). However, false positives also increase (26 vs. 8 previously), indicating a trade-off between sensitivity and precision. The model is now correctly identifying more cases of Glaucoma but at the cost of more false alarms. This might be acceptable or even desirable in medical screening contexts, where missing a diagnosis of Glaucoma can have profound implications, and further testing can rule out false positives."
      ],
      "metadata": {
        "id": "4d68ilsn7AAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The classification report for a binary classification model, with metrics calculated for each class and averages. Here is an analysis of the provided metrics:\n",
        "\n",
        "1. **Not Glaucoma Class:**\n",
        "   - **Precision:** For the \"Not Glaucoma\" class, the precision is 0.75, meaning that when the model predicts an image as \"Not Glaucoma,\" it is correct 75% of the time.\n",
        "   - **Recall:** The recall for \"Not Glaucoma\" is 0.59, indicating that the model correctly identifies 59% of the actual \"Not Glaucoma\" cases.\n",
        "   - **F1-Score:** The F1-score, which balances precision and recall, is 0.66 for \"Not Glaucoma\".\n",
        "   - **Support:** There are 64 instances of \"Not Glaucoma\" in the test set.\n",
        "\n",
        "2. **Glaucoma Class:**\n",
        "   - **Precision:** For \"Glaucoma,\" the precision is lower at 0.43, which means when the model predicts \"Glaucoma,\" it is correct about 43% of the time.\n",
        "   - **Recall:** The model has a higher recall of 0.61 for \"Glaucoma,\" successfully identifying 61% of all actual \"Glaucoma\" cases.\n",
        "   - **F1-Score:** The F1-score for \"Glaucoma\" is 0.51, lower than for \"Not Glaucoma\".\n",
        "   - **Support:** There are 33 instances of \"Glaucoma\" in the test set.\n",
        "\n",
        "3. **Overall Metrics:**\n",
        "   - **Accuracy:** The model's overall accuracy is 0.60, meaning it correctly predicts 60% of both classes combined.\n",
        "   - **Macro Avg:** The macro average for precision and recall is 0.59 and 0.60, respectively, which does not consider class imbalance.\n",
        "   - **Weighted Avg:** The weighted average for precision is 0.64, and for the F1-score is 0.61, which accounts for the class imbalance by weighting the metric of each class by its support.\n",
        "\n",
        "The model has a reasonably balanced precision and recall performance across both classes. However, it performs better in the \"Not Glaucoma\" class than the \"Glaucoma\" class in precision. However, its recall for \"Glaucoma\" is reasonably good, which is often more critical in medical diagnosis scenarios where it is essential to minimize false negatives. The overall accuracy is moderate, and there is a hint of a trade-off between precision and recall, especially in the \"Glaucoma\" class."
      ],
      "metadata": {
        "id": "RmqOSrta9RMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##New Model Architecture"
      ],
      "metadata": {
        "id": "w1Z66tUWBCOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Model Architecture:\n",
        "  - The model has convolutional layers (Conv2D), each followed by max-pooling layers (MaxPooling2D). These layers are used to extract features from the input images.\n",
        "  - After convolutional layers, the network is flattened (flattened) to feed into the dense layers.\n",
        "  - Optionally, a dropout layer is added if the dropout_rate exceeds 0. This helps in reducing overfitting.\n",
        "  - The output layer is dense with a softmax activation function to classify the images into num_classes categories. It also includes L1 and L2 regularization based on\n",
        "  the specified l1_reg and l2_reg.\n",
        "\n",
        "- Function Parameters:\n",
        "  - train_images, train_labels: Training dataset (images and labels).\n",
        "  - test_images, test_labels: Testing dataset.\n",
        "  - num_classes: Number of unique classes in the dataset.\n",
        "  - epochs: Number of training epochs (default is 10).\n",
        "  - validation_split: Fraction of the training data to be used as validation data (default is 0.1).\n",
        "  - batch_size: Number of samples per gradient update (default is 32).\n",
        "  - learning_rate: Learning rate for the optimizer (default is 0.001).\n",
        "  - optimizer: Type of optimizer to use (default is 'adam').\n",
        "  - loss: Loss function (default is 'categorical_crossentropy').\n",
        "  - metrics: List of metrics to be evaluated by the model during training and testing (default is ['accuracy']).\n",
        "  - early_stopping: Boolean to enable early stopping (default is False).\n",
        "  - dropout_rate: Fraction of the input units to drop (default is 0.0).\n",
        "  - l1_reg, l2_reg: L1 and L2 regularization factors (default is 0.0 for both).\n",
        "\n",
        "This code is a typical example of how to set up a CNN for image classification tasks in TensorFlow, with added features like dropout, L1/L2 regularization, and early stopping for better generalization and performance.\n"
      ],
      "metadata": {
        "id": "I9llJdUIDgf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare function to Builds, compiles, and trains a convolutional neural network model\n",
        "def build_and_train_model(train_images, train_labels, test_images, test_labels,\n",
        "                          num_classes, epochs=10,\n",
        "                          validation_split=0.1,\n",
        "                          batch_size=32,\n",
        "                          learning_rate=0.001,\n",
        "                          optimizer='adam',\n",
        "                          loss='categorical_crossentropy',\n",
        "                          metrics=['accuracy'],\n",
        "                          early_stopping=False,\n",
        "                          dropout_rate=0.0,\n",
        "                          l1_reg=0.0,\n",
        "                          l2_reg=0.0):\n",
        "\n",
        "    # Define the input layer\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "    # Convolutional layers with max pooling\n",
        "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "\n",
        "    # Flatten the output\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "    # Dropout layer\n",
        "    if dropout_rate > 0.0:\n",
        "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Regularizers\n",
        "    regularizer = tf.keras.regularizers.l1_l2(l1=l1_reg, l2=l2_reg)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\", kernel_regularizer=regularizer)(x)\n",
        "\n",
        "    # Build the model\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Select optimizer\n",
        "    if optimizer == 'adam':\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "    # Early stopping callback\n",
        "    callbacks = []\n",
        "    if early_stopping:\n",
        "        callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3))\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size, validation_split=validation_split, callbacks=callbacks)\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "\n",
        "    # Print the accuracy results for this model\n",
        "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    return model, test_accuracy\n",
        "\n",
        "# Determine the number of unique classes in the training labels\n",
        "num_classes = len(np.unique(train_labels))\n",
        "\n",
        "# Execute the function to build, compile, and train the model\n",
        "model, test_accuracy = build_and_train_model(train_images, train_labels, test_images, test_labels, num_classes, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyYYc323Lg4J",
        "outputId": "449d6e3f-ec3b-469f-df12-7da610d4aafc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 78s 3s/step - loss: 0.8668 - accuracy: 0.5022 - val_loss: 0.6968 - val_accuracy: 0.4231\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 76s 3s/step - loss: 0.6934 - accuracy: 0.5253 - val_loss: 0.6944 - val_accuracy: 0.4744\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 75s 3s/step - loss: 0.6768 - accuracy: 0.6061 - val_loss: 0.8229 - val_accuracy: 0.4744\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 75s 3s/step - loss: 0.6051 - accuracy: 0.6941 - val_loss: 0.7961 - val_accuracy: 0.4744\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 75s 3s/step - loss: 0.4759 - accuracy: 0.7879 - val_loss: 0.9547 - val_accuracy: 0.3974\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 75s 3s/step - loss: 0.3496 - accuracy: 0.8398 - val_loss: 1.0707 - val_accuracy: 0.4359\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 84s 4s/step - loss: 0.2509 - accuracy: 0.8831 - val_loss: 1.2646 - val_accuracy: 0.4103\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 75s 3s/step - loss: 0.1855 - accuracy: 0.9250 - val_loss: 1.4536 - val_accuracy: 0.4872\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 75s 3s/step - loss: 0.1261 - accuracy: 0.9553 - val_loss: 1.7977 - val_accuracy: 0.3846\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 76s 3s/step - loss: 0.0890 - accuracy: 0.9726 - val_loss: 2.1791 - val_accuracy: 0.4744\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 2.6968 - accuracy: 0.4433\n",
            "Test accuracy: 0.4433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This represents a basic CNN structure with three convolutional layers. A max-pooling layer follows each convolutional layer. The filter sizes increase with each layer (32, 64, 128), a common practice in CNN design to progressively capture more complex features."
      ],
      "metadata": {
        "id": "E4y9cC6quur8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Adjusting Model Architecture"
      ],
      "metadata": {
        "id": "pizjklSrlKmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare function to build, compile, and train a convolutional neural network model\n",
        "def build_and_train_model(train_images, train_labels, test_images, test_labels,\n",
        "                          num_classes, epochs=10,\n",
        "                          validation_split=0.1,\n",
        "                          batch_size=32,\n",
        "                          learning_rate=0.001,\n",
        "                          optimizer='adam',\n",
        "                          loss='categorical_crossentropy',\n",
        "                          metrics=['accuracy'],\n",
        "                          early_stopping=False,\n",
        "                          dropout_rate=0.0,\n",
        "                          l1_reg=0.0,\n",
        "                          l2_reg=0.0,\n",
        "                          activation='relu'):  # Added activation parameter\n",
        "\n",
        "    # Define the input layer\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "    # Convolutional layers with max pooling - modified structure\n",
        "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=activation)(inputs)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=activation)(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=activation)(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation=activation)(x)  # New layer added\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "\n",
        "    # Flatten the output\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "    # Dropout layer\n",
        "    if dropout_rate > 0.0:\n",
        "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Regularizers\n",
        "    regularizer = tf.keras.regularizers.l1_l2(l1=l1_reg, l2=l2_reg)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\", kernel_regularizer=regularizer)(x)\n",
        "\n",
        "    # Build the model\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Select optimizer\n",
        "    if optimizer == 'adam':\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "    # Early stopping callback\n",
        "    callbacks = []\n",
        "    if early_stopping:\n",
        "        callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3))\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size, validation_split=validation_split, callbacks=callbacks)\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "\n",
        "    # Print the accuracy results for this model\n",
        "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    return model, test_accuracy\n",
        "\n",
        "# Determine the number of unique classes in the training labels\n",
        "num_classes = len(np.unique(train_labels))\n",
        "\n",
        "# Execute the function to build, compile, and train the model\n",
        "model, test_accuracy = build_and_train_model(train_images, train_labels, test_images, test_labels, num_classes, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbXYAz0vlwA2",
        "outputId": "3d0b294a-86d5-461a-d0d3-1fc45c0a57bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 93s 4s/step - loss: 0.6956 - accuracy: 0.4921 - val_loss: 0.6932 - val_accuracy: 0.4359\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 92s 4s/step - loss: 0.6943 - accuracy: 0.5036 - val_loss: 0.6962 - val_accuracy: 0.4744\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 92s 4s/step - loss: 0.6942 - accuracy: 0.5108 - val_loss: 0.6998 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 96s 4s/step - loss: 0.6842 - accuracy: 0.5844 - val_loss: 0.7066 - val_accuracy: 0.4231\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 91s 4s/step - loss: 0.6634 - accuracy: 0.5931 - val_loss: 0.7458 - val_accuracy: 0.4487\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 91s 4s/step - loss: 0.6335 - accuracy: 0.6320 - val_loss: 0.8639 - val_accuracy: 0.5256\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 91s 4s/step - loss: 0.5899 - accuracy: 0.6465 - val_loss: 0.8620 - val_accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 93s 4s/step - loss: 0.5349 - accuracy: 0.6955 - val_loss: 1.0830 - val_accuracy: 0.4487\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 92s 4s/step - loss: 0.4940 - accuracy: 0.7143 - val_loss: 1.0552 - val_accuracy: 0.4615\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 91s 4s/step - loss: 0.4518 - accuracy: 0.7720 - val_loss: 1.6242 - val_accuracy: 0.4872\n",
            "4/4 [==============================] - 3s 661ms/step - loss: 1.3505 - accuracy: 0.4742\n",
            "Test accuracy: 0.4742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyzing the differences between the two Models**:\n",
        "\n",
        "1. **Additional Convolutional Layer**:\n",
        "   - **First Code**: Has three convolutional layers.\n",
        "   - **Second Code**: Introduces a fourth convolutional layer with 256 filters.\n",
        "   - **Analysis**: Additional layers can help the network learn more complex patterns, contributing to increased accuracy in the second model.\n",
        "\n",
        "2. **Max Pooling Layers**:\n",
        "   - **Both Codes**: Include max pooling layers after each convolutional layer.\n",
        "   - **Analysis**: Max pooling is consistent in both, and it is standard in CNN architectures for downscaling feature maps and reducing computational load.\n",
        "\n",
        "3. **Activation Function as a Parameter**:\n",
        "   - **First Code**: Uses ReLU activation hardcoded.\n",
        "   - **Second Code**: Adds an 'activation' parameter, although it defaults to 'ReLU'.\n",
        "   - **Analysis**: This change does not affect the model's performance since ReLU is used in both cases. However, having it as a parameter adds flexibility for future adjustments.\n",
        "\n",
        "4. **Dropout, Regularization, and Other Parameters**:\n",
        "   - **Both Codes**: Dropout rate, L1 and L2 regularizations, and other parameters like learning rate, loss function, and optimizer are consistent.\n",
        "   - **Analysis**: No impact on the difference in performance due to these factors.\n",
        "\n",
        "**Suggestions for Further Improvement**:\n",
        "\n",
        "1. **Data Augmentation**:\n",
        "   - Consider using data augmentation techniques to increase the diversity of the training data, which can improve the model's ability to generalize.\n",
        "\n",
        "2. **Tuning Hyperparameters**:\n",
        "   - Experiment with different values for batch size, learning rate, and number of epochs.\n",
        "   - Adjust the dropout rate to prevent overfitting.\n",
        "   - Try different regularization strengths.\n",
        "\n",
        "3. **Modify Network Architecture**:\n",
        "   - Experiment with different numbers of filters and kernel sizes in convolutional layers.\n",
        "   - Add more convolutional layers or reduce them if the model is too complex and overfitting.\n",
        "   - Try using different types of layers like Batch Normalization or different pooling strategies.\n",
        "\n",
        "4. **Advanced Optimizers**:\n",
        "   - Beyond Adam, explore other optimizers like SGD with momentum, RMSprop, etc., which might yield better results in specific scenarios.\n",
        "\n",
        "5. **Use of pre-trained Models**:\n",
        "   - Implement transfer learning with pre-trained models like ResNet, VGGNet, etc., which can significantly boost performance, especially with limited data.\n",
        "\n",
        "6. **Fine-Tuning Activation Functions**:\n",
        "   - Experiment with activation functions like LeakyReLU, ELU, or Swish to see if they offer performance benefits.\n",
        "\n",
        "7. **Early Stopping and Callbacks**:\n",
        "   - Utilize early stopping more effectively to avoid overfitting.\n",
        "   - Use additional callbacks like ModelCheckpoint to save the best model during training.\n",
        "\n",
        "8. **Layer-Specific Adjustments**:\n",
        "   - Consider adjusting the pooling sizes or strides in convolutional layers to see how they affect model performance.\n",
        "\n",
        "9. **Evaluation on a Validation Set**:\n",
        "   - Besides test set evaluation, regularly evaluate the model on a separate validation set during training to monitor performance and adjust accordingly.\n",
        "\n",
        "10. **Error Analysis**:\n",
        "    - Perform error analysis to understand where the model is making mistakes and if there are specific patterns or classes where it is underperforming.\n"
      ],
      "metadata": {
        "id": "vB0LxSfSCROu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tuning Hyperparameters"
      ],
      "metadata": {
        "id": "J5eIvuUXDnHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Experiment with different values for batch size, learning rate, and number of epochs"
      ],
      "metadata": {
        "id": "xXo2I1sKEDTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare function to build, compile, and train a convolutional neural network model\n",
        "def build_and_train_model(train_images, train_labels, test_images, test_labels,\n",
        "\n",
        "                          num_classes, epochs=20, # Changed from 10 to 20\n",
        "                          validation_split=0.1,\n",
        "                          batch_size=64,          # Changed from 32 to 64\n",
        "                          learning_rate=0.0005,   # Changed from 0.001 to 0.0005\n",
        "                          optimizer='adam',\n",
        "                          loss='categorical_crossentropy',\n",
        "                          metrics=['accuracy'],\n",
        "                          early_stopping=False,\n",
        "                          dropout_rate=0.0,\n",
        "                          l1_reg=0.0,\n",
        "                          l2_reg=0.0,\n",
        "                          activation='relu'):\n",
        "\n",
        "    # Define the input layer\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "    # Convolutional layers with max pooling\n",
        "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=activation)(inputs)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=activation)(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=activation)(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "    x = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation=activation)(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "\n",
        "    # Flatten the output\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "    # Dropout layer\n",
        "    if dropout_rate > 0.0:\n",
        "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Regularizers\n",
        "    regularizer = tf.keras.regularizers.l1_l2(l1=l1_reg, l2=l2_reg)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\", kernel_regularizer=regularizer)(x)\n",
        "\n",
        "    # Build the model\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Select optimizer\n",
        "    if optimizer == 'adam':\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "    # Early stopping callback\n",
        "    callbacks = []\n",
        "    if early_stopping:\n",
        "        callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3))\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size, validation_split=validation_split, callbacks=callbacks)\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "\n",
        "    # Print the accuracy results for this model\n",
        "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    return model, test_accuracy\n",
        "\n",
        "# Determine the number of unique classes in the training labels\n",
        "num_classes = len(np.unique(train_labels))\n",
        "\n",
        "# Execute the function to build, compile, and train the model\n",
        "model, test_accuracy = build_and_train_model(train_images, train_labels, test_images, test_labels, num_classes, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "id": "HnC8wzD5EJaN",
        "outputId": "dbe91651-b99c-4344-bfc8-5d34b2582114",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "11/11 [==============================] - 111s 10s/step - loss: 0.7064 - accuracy: 0.4978 - val_loss: 0.6932 - val_accuracy: 0.4872\n",
            "Epoch 2/10\n",
            "11/11 [==============================] - 97s 9s/step - loss: 0.6932 - accuracy: 0.5094 - val_loss: 0.6942 - val_accuracy: 0.4872\n",
            "Epoch 3/10\n",
            "11/11 [==============================] - 93s 8s/step - loss: 0.6894 - accuracy: 0.5859 - val_loss: 0.6997 - val_accuracy: 0.4872\n",
            "Epoch 4/10\n",
            "11/11 [==============================] - 105s 9s/step - loss: 0.6841 - accuracy: 0.5743 - val_loss: 0.7110 - val_accuracy: 0.4872\n",
            "Epoch 5/10\n",
            "11/11 [==============================] - 94s 9s/step - loss: 0.6737 - accuracy: 0.5916 - val_loss: 0.7126 - val_accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "11/11 [==============================] - 94s 9s/step - loss: 0.6578 - accuracy: 0.6595 - val_loss: 0.7272 - val_accuracy: 0.5641\n",
            "Epoch 7/10\n",
            "11/11 [==============================] - 94s 8s/step - loss: 0.6603 - accuracy: 0.6291 - val_loss: 0.7035 - val_accuracy: 0.4615\n",
            "Epoch 8/10\n",
            "11/11 [==============================] - 96s 9s/step - loss: 0.6275 - accuracy: 0.6667 - val_loss: 0.7623 - val_accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "11/11 [==============================] - 94s 9s/step - loss: 0.5939 - accuracy: 0.6782 - val_loss: 0.8376 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "11/11 [==============================] - 94s 9s/step - loss: 0.5595 - accuracy: 0.6941 - val_loss: 0.8207 - val_accuracy: 0.5385\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.9243 - accuracy: 0.4227\n",
            "Test accuracy: 0.4227\n"
          ]
        }
      ]
    }
  ]
}