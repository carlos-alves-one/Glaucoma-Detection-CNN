{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPLaf3PrWsfrX9lhu1mjaJ4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlos-alves-one/-AI-Coursework-1/blob/main/glaucoma_detection_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goldsmiths University of London\n",
        "### MSc. Data Science and Artificial Intelligence\n",
        "### Module: Artificial Intelligence\n",
        "### Author: Carlos Manuel De Oliveira Alves\n",
        "### Student: cdeol003\n",
        "### Coursework No.1"
      ],
      "metadata": {
        "id": "tBKBzWjS13MG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "q7mllJDHrgkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this research is to outline the progression of a deep-learning model designed to identify glaucoma through the analysis of ocular pictures. Glaucoma is a debilitating ocular disorder that, if left undetected and untreated in its early stages, can result in complete vision loss. Effective screening procedures are necessary due to the asymptomatic nature of the early stages of glaucoma. Deep learning, specifically convolutional neural networks (CNNs), has demonstrated considerable potential in image identification tasks and can aid in the early detection of glaucoma. The dataset utilised in this research comprises a collection of ocular pictures accompanied by a binary classification showing the presence or absence of glaucoma. The ExpCDR, or 'Cup to Disc Ratio', is a crucial clinical parameter utilised in evaluating glaucoma for each image."
      ],
      "metadata": {
        "id": "5nmnsNVsr8qW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology"
      ],
      "metadata": {
        "id": "3b-dTV8Vt49g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "MY2ytKpmt738"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The photos will undergo a process of loading, resizing to a consistent dimension, and normalisation to ensure that their pixel values fall within the range of 0 to 1. Furthermore, it is possible to employ data augmentation methods, such as rotations, shifts, and flips, in order to augment the size and diversity of the dataset. This can be beneficial in mitigating the issue of overfitting."
      ],
      "metadata": {
        "id": "D6BrGaKKuGCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the data"
      ],
      "metadata": {
        "id": "jn_YNcXj8IEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pandas library and give it the alias 'pd' for data manipulation and analysis\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset glaucoma\n",
        "data_path = 'glaucoma.csv'\n",
        "glaucoma_data = pd.read_csv(data_path)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "glaucoma_data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "izSxt6H1yRKF",
        "outputId": "0e193767-51e8-40cc-da65-45a1442c55fe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Filename  ExpCDR Eye Set  Glaucoma\n",
              "0  001.jpg  0.7097  OD   A         0\n",
              "1  002.jpg  0.6953  OS   A         0\n",
              "2  003.jpg  0.9629  OS   A         0\n",
              "3  004.jpg  0.7246  OD   A         0\n",
              "4  005.jpg  0.6138  OS   A         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5416a0e-f776-4e2f-bb05-bfc806d98806\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>ExpCDR</th>\n",
              "      <th>Eye</th>\n",
              "      <th>Set</th>\n",
              "      <th>Glaucoma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001.jpg</td>\n",
              "      <td>0.7097</td>\n",
              "      <td>OD</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002.jpg</td>\n",
              "      <td>0.6953</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>003.jpg</td>\n",
              "      <td>0.9629</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004.jpg</td>\n",
              "      <td>0.7246</td>\n",
              "      <td>OD</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>005.jpg</td>\n",
              "      <td>0.6138</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5416a0e-f776-4e2f-bb05-bfc806d98806')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a5416a0e-f776-4e2f-bb05-bfc806d98806 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a5416a0e-f776-4e2f-bb05-bfc806d98806');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b7ca2bd9-1d6d-4909-8e27-7fe9846978c0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7ca2bd9-1d6d-4909-8e27-7fe9846978c0')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b7ca2bd9-1d6d-4909-8e27-7fe9846978c0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset source: https://www.kaggle.com/datasets/sshikamaru/glaucoma-detection"
      ],
      "metadata": {
        "id": "0Wkii1gYzyP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "License: CC0 - Public Domain\n",
        "https://creativecommons.org/publicdomain/zero/1.0/"
      ],
      "metadata": {
        "id": "aH2Ggn2F1iVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains the following columns:\n",
        "\n",
        "    - Filename: The name of the image file.\n",
        "    - ExpCDR: The 'Cup to Disc Ratio', a crucial parameter for evaluating glaucoma.\n",
        "    - Eye: Indicates which eye the image corresponds to (OD for right eye, OS for left eye).\n",
        "    - Set: This could denote the dataset split (e.g., training, validation, or test set), but we would need further clarification.\n",
        "    - Glaucoma: The binary label indicating the presence (1) or absence (0) of glaucoma."
      ],
      "metadata": {
        "id": "R7pF7QJBzWJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocess the Data"
      ],
      "metadata": {
        "id": "kIRg-zv18Wdc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declare function to preprocess a single image:"
      ],
      "metadata": {
        "id": "G3MorKQz8imc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the os module for interacting with the operating system and tensorflow for machine learning tasks\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Function to preprocess a single image\n",
        "def preprocess_image(filename, img_height=224, img_width=224, images_directory='/images'):\n",
        "\n",
        "    # Join the directory path and filename to form the full path to an image\n",
        "    image_path = os.path.join(images_directory, filename)\n",
        "\n",
        "    # Read the image file from the specified path into a tensor\n",
        "    image = tf.io.read_file(image_path)\n",
        "\n",
        "    # Decode the JPEG image and ensure it has 3 color channels (RGB)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "    # Resize the image to the specified height and width using TensorFlow's resize function\n",
        "    image = tf.image.resize(image, [img_height, img_width])\n",
        "\n",
        "    # Normalize the image pixels to the range 0-1 for model compatibility\n",
        "    image = image / 255.0\n",
        "\n",
        "    # Return image preprocessed\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "8Cor34I5zW5T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Augmentation"
      ],
      "metadata": {
        "id": "GRaJvgNZA7Kq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up data augmentation using the ImageDataGenerator class from tf.keras.preprocessing.image."
      ],
      "metadata": {
        "id": "GvGPtNgGBH2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the ImageDataGenerator class from TensorFlow's Keras API for real-time data augmentation of images\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set up data augmentation\n",
        "data_augmentation = ImageDataGenerator(\n",
        "\n",
        "    # Configures the image augmentation by rotating images within 20 degrees randomly\n",
        "    rotation_range=20,\n",
        "\n",
        "    # Specifies that the input width can be shifted by a maximum of 20% either left or right\n",
        "    width_shift_range=0.2,\n",
        "\n",
        "    # Randomly shift the height of images during training by a factor of 20%\n",
        "    height_shift_range=0.2,\n",
        "\n",
        "    # Enables horizontal and vertical flipping of images\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "egiwJVWcBHCW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Apply Preprocessing and Augmentation to Dataset"
      ],
      "metadata": {
        "id": "vOjBVhxXCtOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract filenames and corresponding glaucoma presence labels from the dataset\n",
        "filenames = glaucoma_data['Filename'].values\n",
        "labels = glaucoma_data['Glaucoma'].values\n",
        "\n",
        "# A placeholder for the images directory\n",
        "images_directory = '/content/images'\n",
        "\n",
        "# Preprocess all images\n",
        "images = [preprocess_image(f, images_directory=images_directory) for f in filenames]\n",
        "\n",
        "# Convert to Tensor\n",
        "images = tf.stack(images)\n",
        "labels = tf.convert_to_tensor(labels)\n"
      ],
      "metadata": {
        "id": "zRzwzMliCuaV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture\n",
        "The model will be a CNN, known for its performance in image classification tasks. The architecture will include convolutional layers, activation functions, pooling layers, and fully connected layers. Dropout layers may be included to reduce overfitting."
      ],
      "metadata": {
        "id": "1rw1b7WzG_P8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Process\n",
        "The dataset will be split into training, validation, and test sets. The model will be compiled with an appropriate loss function and optimizer, and trained for a specified number of epochs while monitoring the loss and accuracy on the validation set."
      ],
      "metadata": {
        "id": "k7aEha11HqEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split function from scikit-learn to split data into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import TensorFlow for deep learning and train_test_split function for splitting the dataset into training and testing sets\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Let's say images_tensor and labels_tensor are your TensorFlow tensors\n",
        "images_numpy = images.numpy()\n",
        "labels_numpy = labels.numpy()\n",
        "\n",
        "# Now you can use train_test_split on NumPy arrays\n",
        "train_images, val_test_images, train_labels, val_test_labels = train_test_split(\n",
        "    images_numpy, labels_numpy, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Split the val_test set equally into validation and test sets (50% validation, 50% test)\n",
        "val_images, test_images, val_labels, test_labels = train_test_split(\n",
        "    val_test_images, val_test_labels, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "emTnln6HQhGF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the CNN model architecture\n",
        "def build_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')  # Sigmoid activation for binary classification\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Assuming the input images are 224x224 pixels with 3 channels (RGB)\n",
        "input_shape = (224, 224, 3)\n",
        "model = build_model(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# We will need to split the dataset into training, validation, and test sets\n",
        "# For the purposes of this example, let's assume that we have already split the data\n",
        "# and have the following tensors: train_images, train_labels, val_images, val_labels\n",
        "# We would also need to specify the batch size and number of epochs for training\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(val_images, val_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SBIwCjOPxyR",
        "outputId": "d73c8171-b525-492a-8464-eb627357c228"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "17/17 [==============================] - 15s 111ms/step - loss: 0.7028 - accuracy: 0.6885 - val_loss: 0.5860 - val_accuracy: 0.7538\n",
            "Epoch 2/10\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 0.5992 - accuracy: 0.7423 - val_loss: 0.5602 - val_accuracy: 0.7538\n",
            "Epoch 3/10\n",
            "17/17 [==============================] - 1s 60ms/step - loss: 0.5733 - accuracy: 0.7423 - val_loss: 0.5605 - val_accuracy: 0.7538\n",
            "Epoch 4/10\n",
            "17/17 [==============================] - 1s 54ms/step - loss: 0.5810 - accuracy: 0.7423 - val_loss: 0.5834 - val_accuracy: 0.7538\n",
            "Epoch 5/10\n",
            "17/17 [==============================] - 1s 53ms/step - loss: 0.5849 - accuracy: 0.7423 - val_loss: 0.5738 - val_accuracy: 0.7538\n",
            "Epoch 6/10\n",
            "17/17 [==============================] - 1s 63ms/step - loss: 0.5893 - accuracy: 0.7423 - val_loss: 0.5628 - val_accuracy: 0.7538\n",
            "Epoch 7/10\n",
            "17/17 [==============================] - 1s 57ms/step - loss: 0.5650 - accuracy: 0.7423 - val_loss: 0.5889 - val_accuracy: 0.7538\n",
            "Epoch 8/10\n",
            "17/17 [==============================] - 1s 54ms/step - loss: 0.5661 - accuracy: 0.7423 - val_loss: 0.5879 - val_accuracy: 0.7538\n",
            "Epoch 9/10\n",
            "17/17 [==============================] - 1s 53ms/step - loss: 0.5632 - accuracy: 0.7423 - val_loss: 0.5665 - val_accuracy: 0.7538\n",
            "Epoch 10/10\n",
            "17/17 [==============================] - 1s 54ms/step - loss: 0.5658 - accuracy: 0.7423 - val_loss: 0.5697 - val_accuracy: 0.7538\n"
          ]
        }
      ]
    }
  ]
}